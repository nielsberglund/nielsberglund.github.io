<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Niels Berglund</title>
  <link href="https://nielsberglund.com/atom.xml" rel="self"/>
  <link href="https://nielsberglund.com"/>
  <updated>2020-12-21T09:18:00+02:00</updated>
  <id>https://nielsberglund.com/</id>
  <generator uri="http://gohugo.io/">Hugo</generator>

  
  <entry>
    <title type="html"><![CDATA[A Lap Around SQL Server 2019 Big Data Cluster: Architecture]]></title>
    <link href="https://nielsberglund.com/2020/12/21/a-lap-around-sql-server-2019-big-data-cluster-architecture/" rel="alternate" type="text/html"/>
    <updated>2020-12-21T09:18:00+02:00</updated>
    <id>https://nielsberglund.com/2020/12/21/a-lap-around-sql-server-2019-big-data-cluster-architecture/</id>
    <content type="html"><![CDATA[<p>This post is the second in series about <strong>SQL Server 2019 Big Data Cluster</strong> based on a presentation I do: <strong>A Lap Around SQL Server 2019 Big Data Cluster</strong>.</p>

<p>In the first post <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/"><strong>A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</strong></a> we looked at - as the title implies - the background of SQL Server 2019 Big Data Cluster, (BDC), and the technology behind it.</p>

<p>In this post, we look at the architecture and components of a BDC.</p>

<p></p>

<p>Before we dive into the architecture, let&rsquo;s refresh our memories around what we covered in the <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">previous</a> post.</p>

<h2 id="recap">Recap</h2>

<p>We are getting more and more data, and the data comes in all types and sizes. We need a system to be able to manage, integrate, and analyze all this data. That&rsquo;s where SQL Server comes into the picture.</p>

<p>SQL Server has continuously evolved from its very humble beginnings based on Ashton Tate/Sybase code-base to where it is now:</p>

<ul>
<li>SQL Server in Linux.</li>
<li>SQL Server in Containers.</li>
<li>SQL Server on Kubernetes.</li>
</ul>

<p>With all the capabilities now in SQL Server, it is the ideal platform to handle big data.</p>

<p>The SQL Server itself is not enough to achieve what we want, so in addition to SQL Server a BDC includes quite a few open-source technologies:</p>

<ul>
<li>Apache Spark</li>
<li>Hadoop File System (HDFS)</li>
<li>Influx DB</li>
<li>Graphana</li>
<li>Kibana</li>
<li>Elasticsearch</li>
<li>more &hellip;</li>
</ul>

<p>Oh, and a BDC is not only one SQL server, but quite a few instances. The SQL Server instances are SQL on Linux containers, and the whole BDC are deployed to and runs on Kubernetes (k8s).</p>

<p>We spoke a bit about k8s, and what constitutes a k8s cluster, (nodes, pods, etc.). In the post we tried to illustrate a k8s cluster like so:</p>

<p><img src="/images/posts/bdc-lap-around-bdc-kubernetes-1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Kubernetes</em></p>

<p>In <em>Figure 1</em> we see some of the parts of a two-node Kubernetes cluster, with a Master node. Later in this post, we talk some more about the Master node, and the role it plays.</p>

<p>In the post, we briefly mentioned how we deploy a BDC, and we said we have essentially two options:</p>

<ul>
<li>Deploy via Python scripts.</li>
<li>Deploy using <strong>Azure Data Studio</strong>.</li>
</ul>

<p>We looked at how to manage and monitor a BDC, and we spoke about the tools for managing and monitoring:</p>

<ul>
<li><code>kubectl</code> - used to manage the Kubernetes cluster the BDC is deployed to.</li>
<li><code>azdata</code> - manage the BDC.</li>
</ul>

<p>In this post, looking at the architecture, we use the tools above, so ensure you have them installed if you want to follow along.</p>

<h2 id="architecture">Architecture</h2>

<p>How can we figure out what the architecture looks like? Well, in the <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/"><strong>A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</strong></a> post, we discussed k8s pods and how we could get information about the pod by executing some <code>kubectl</code> commands.</p>

<p>So let us go back to the pod we looked at briefly in the last post: <code>master-0</code>, which is the pod containing the SQL Server master instance. We look at that pod to see if we can get some information from it, which will help us in gaining insight into the architecture of a BDC. The code we use looks like so:</p>

<pre><code class="language-bash">kubectl get pods master-0 -n sqlbdc-cluster -o JSON
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Get Pod Information</em></p>

<p>In <em>Code Snippet 1</em> above we see how we use <code>kubectl get pods</code> and we:</p>

<ul>
<li>Send in the name of the pod we are interested in,</li>
<li>Indicate the k8s namespace the pod is in.</li>
<li>Want the output, <code>-o</code> flag, formatted as JSON.</li>
</ul>

<p>When we execute the code in <em>Code Snippet 1</em> we see something like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-pods1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Get Pods</em></p>

<p>The <code>kubectl get pods master-0</code> command returns all information about that particular pod, and in <em>Figure 2</em> we see the first 20 lines or so of the JSON output.</p>

<p>Notice the section outlined in red, the <code>metadata</code> section. This section contains general information about the pod, and if we look closer, we can see three labels outlined in, purple, yellow and green respectively:</p>

<ul>
<li><code>app</code> with a value of <code>master</code>.</li>
<li><code>plane</code> with a value of <code>data</code>.</li>
<li><code>role</code> with a value of <code>master-pool</code>.</li>
</ul>

<p>Maybe these labels would give us some insight if we were to look at all pods? Ok, so let&rsquo;s do that, and we will use some <code>kubectl -o</code> &ldquo;magic&rdquo; to get the information we want:</p>

<pre><code class="language-bash">kubectl get pods -n sqlbdc-cluster \ 
                 -o custom-columns=NAME:.metadata.name, \
                    APP:.metadata.labels.app, \
                    ROLE:.metadata.labels.role,\
                    PLANE:.metadata.labels.plane
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Custom Columns</em></p>

<p>To retrieve the information we want, we use the <code>custom-columns</code> output option. We see in <em>Code Snippet 2</em> how we say we want four columns back: <code>NAME</code>, <code>APP</code>, <code>ROLE, and</code>PLANE`, and what labels those are, (we talk more about labels below). We then execute:</p>

<p><img src="/images/posts/bdc-lap-around-arch-roles-planes.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Pods with Custom Output</em></p>

<p>In <em>Figure 3</em> we see the result from executing the code in <em>Code Snippet 2</em> and we see all pods in the <code>sqlbdc-cluster</code> namespace, i.e. all pods in the BDC. From the <code>PLANE</code> column we see how the BDC has two planes, the control plane and the data plane.</p>

<h4 id="control-data-plane">Control &amp; Data Plane</h4>

<p>Let us make a short diversion here and talk a bit about control and data planes.</p>

<p>In distributed systems/services, we need a way to manage and monitor our services, and that is the role of the control plane. In the previous <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">post</a> we spoke about the master node in a k8s cluster and how we interact with the master node for management of the cluster.</p>

<p>However, k8s has no idea about a SQL Server 2019 Big Data Cluster; in which order pods should be deployed etc. This is where the BDC control plane comes in. It knows about the BDC, so whenever there needs to be an interaction between the Kubernetes cluster and the BDC the k8s master node interacts with the BDC&rsquo;s control plane. Take a deployment as an example; when deploying to the BDC, the control plane acts as the coordinator and ensures services, etc., are &ldquo;spun up&rdquo; in the correct order.</p>

<p>That is, however, not the only thing the control plane does. Remember from my previous <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">post</a> how we briefly discussed monitoring of a BDC and how we said we use Grafana, and Kibana together with the underlying InfluxDB and EleasticSearch as persistent stores. Well, the control plane is also responsible for monitoring, and in <em>Figure 3</em> you see some examples of this, where there are <code>APP</code>&rsquo;s related to logs and metrics.</p>

<p>The data plane is what we communicate with when working with the BDC, doing queries etc. - the application traffic. In addition to that, the data plane is also responsible for:</p>

<ul>
<li>Routing.</li>
<li>Load balancing.</li>
<li>Observability.</li>
</ul>

<p>Now, knowing a bit about the planes, let us have a look at roles.</p>

<h4 id="role">role</h4>

<p>In Kubernetes, you have the notion of a <code>Role</code>, and that has to do with security: a <code>Role</code> sets permissions within a namespace. The <code>role</code> I refer to here has nothing to do with that. No, a <code>role</code> in this context is a label attributed to a pod in a k8s cluster.</p>

<blockquote>
<p><strong>NOTE:</strong> In <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">k8s documentation Labels</a> are described as follows: &ldquo;Labels are key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Labels can be used to organize and to select subsets of objects.&rdquo;</p>
</blockquote>

<p>Seeing the description about Labels above, we can deduce that a <code>role</code> describes the &ldquo;role&rdquo; of a Kubernetes component, i.e. what it does or belongs to. With that in mind, we can get some information/insight around the architecture of the BDC from it.</p>

<p>So let us once again look at the pods in the cluster and see what the <code>role</code> labels tell us:</p>

<pre><code class="language-bash">kubectl get pods -n sqlbdc-cluster2 \
                 -o custom-columns=PODNAME:.metadata.name,\
                 ROLE:.metadata.labels.role
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Pods &amp; Roles</em></p>

<p>The code in <em>Code Snippet 3</em> above is almost the same as in <em>Code Snippet 2</em>, but without the <code>APP</code> and <code>PLANE</code> columns. When we execute, we see:</p>

<p><img src="/images/posts/bdc-lap-around-arch-roles2.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Pods with Custom Output</em></p>

<p>In <em>Figure 4</em> we see how the various pods belong to quite few <code>ROLE</code>&rsquo;s. Some of the <code>ROLE</code>&rsquo;s we see are familiar, like: <code>controller</code> and <code>monitoring</code>, and we will not talk about them that much more. However, in <em>Figure 4</em> we also see some <code>ROLE</code>s named <code>xxx-pool</code>. Above we said that the <code>master-0</code> belonged to a role named <code>master-pool</code>, and we see that in <em>Figure 4</em> as well.</p>

<p>It turns out that the functionality, (SQL Server Master, Hadoop, etc.), of a BDC, is split into pools.</p>

<h2 id="pools">Pools</h2>

<p>When looking at <em>Figure 4</em> we see that we have different type of pools, and some of them have more than one pod. The pools are:</p>

<ul>
<li><code>compute-pool</code></li>
<li><code>data-pool</code></li>
<li><code>master-pool</code></li>
<li><code>storage-pool</code></li>
</ul>

<p>Let us look somewhat more in-depth into the pools above.</p>

<h4 id="master-pool">Master Pool</h4>

<p>From above we see how <code>master-0</code> belongs to the <code>master-pool</code>. In the last post as well as in this, we have mentioned how the <code>master-0</code> pod represents the SQL Server master instance, i.e. the &ldquo;normal&rdquo; SQL Server where your OLTP databases sit. So, let us see if we can prove that, by looking at what containers the pod has:</p>

<pre><code class="language-bash"> kubectl get pods master-0 -n sqlbdc-cluster2 \
                  -o custom-columns=PODNAME:.metadata.name,\
                     ROLE:.metadata.labels.role,\
                     CONTAINERS:.spec.containers[*].name
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Master Pod Containers</em></p>

<p>The code in <em>Code Snippet 4</em> is almost the same as in <em>Code Snippet 3</em>. The difference is that we also want to see the containers in the pod. When executing, we get:</p>

<p><img src="/images/posts/bdc-lap-around-arch-master-0-containers.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Containers in Master Pod</em></p>

<p>We see in <em>Figure 5</em> that the <code>master-0</code> pod is part of the <code>master-pool</code>, and it consists of three containers. From the <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">previous post</a> we already know about <code>collectd</code> and <code>fluentbit</code>. It is the third container, (first in the list), that is interesting - <code>mssql-server</code>, (highlighted in yellow).</p>

<p>To find out some more about the container we change the code in <em>Code Snippet 4</em> to the following:</p>

<pre><code class="language-bash"> kubectl get pods master-0 -n sqlbdc-cluster2 \
                  -o custom-columns=PODNAME:.metadata.name,\
                     CONTAINERS:.spec.containers[0].name,\
                     IMAGE:.spec.containers[0].image
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Container Image</em></p>

<p>In the code in <em>Code Snippet 5</em> we see how we retrieve the first container and the first image in the pod. We assume that as the SQL Server container is listed first, (see <em>Figure 5</em>), the container image will also be first. When we execute the code, the result looks like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-master-0-image.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>Containers in Master Pod</em></p>

<p>What we see in <em>Figure 6</em> is that the SQL Server instance in the master pool is SQL Server 2019 CU8, and it is SQL Server on Linux.</p>

<p>We will see later how there are more SQL Server instances in a BDC, but the master instance is what the user is interacting with. The master instance is also where read-write OLTP or dimensional data is stored, something like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-master-pool.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>BDC and Master Pool</em></p>

<p>What <em>Figure 7</em> shows us is a partial BDC cluster. The left is the control plane as discussed above and then beside it is the master pool with the one SQL Server instance.</p>

<p>At the bottom - outlined in red - we see a screen which illustrates a user and the interaction with the master instance. We also see a picture showing data stores (outlined in blue). What this means is that in SQL Server 2019, (not only BDC), you can query other data stores outside of SQL Server. This is thanks to Data Virtualization and PolyBase.</p>

<blockquote>
<p><strong>NOTE:</strong> A future post will cover Data Virtualization in SQL Server 2019 BDC.</p>
</blockquote>

<p>So, that is the master pool and the SQL Server master instance, what is next?</p>

<h4 id="compute-pool">Compute Pool</h4>

<p>In <em>Figure 4</em> we see how we have one pod belonging to the compute pool, the <code>compute-0-0</code>. Let us find out what containers are in the pod. We use code similar to <em>Code Snippet 4</em>, and when we execute we see:</p>

<p><img src="/images/posts/bdc-lap-around-arch-compute-containers.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Compute Pool Containers</em></p>

<p>Hmm, the compute pool pod looks the same as the master pool pod - a SQL Server instance. If we were to look at the container images, we&rsquo;d see the same as the master instance. So what is this?</p>

<p>As the name implies, the compute pool provides scale-out computational resources for a SQL Server BDC. They are used to offload computational work, or intermediate result sets, from the SQL Server master instance. For you who have worked with PolyBase before it is a fully configured Polybase Scale-Out Group.</p>

<p>The SQL Server instance in the compute pool is - as mentioned before - for computational purposes, not for storing data. The only time there may be data persistence is if it is needed for data shuffling, and in that case, <code>tempdb</code> is used.</p>

<p>If we add the compute pool to what we have in <em>Figure 7</em> we get something like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-compute-pool.png" alt="" /></p>

<p><strong>Figure 9:</strong> <em>Compute Pool</em></p>

<p>By looking at <em>Figure 9</em> we understand that the compute pool is mostly used when accessing external data, and we see more of this as we go along.</p>

<h4 id="data-pool">Data Pool</h4>

<p>When we look at <em>Figure 4</em> we see we have two pods belonging to the data pool. Let us run the same code as in <em>Figure 8</em> but replace <code>compute-0-0</code> with <code>data-0-0</code> and see what we get:</p>

<p><img src="/images/posts/bdc-lap-around-arch-data-0-containers.png" alt="" /></p>

<p><strong>Figure 10:</strong> <em>Data Pool &amp; Containers</em></p>

<p>In <em>Figure 10</em> we see the same as for the pods in the master and data pools, and if we looked at the second pod it would be the same; one SQL Server instance, together with <code>collectd</code> and <code>fluentbit</code>. So the only difference between the data pool and the other pools is that we have two SQL Server pods in the data pool. Building on the architectural diagram, it looks like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-data-pool.png" alt="" /></p>

<p><strong>Figure 11:</strong> <em>Data Pool</em></p>

<p>We see the data pool in <em>Figure 11</em>, and how it has the two SQL Server instances mentioned above. The reason it has two is that the data pool acts as a persisting and caching layer of external data. The data pool allows for performance querying of cached data against external data sources and offloading of work.</p>

<p>You ingest data into the data pool using either T-SQL queries or from Spark jobs. When you ingest data into the pool, the data is distributed into shards and stored across all SQL Server instances in the pool.</p>

<blockquote>
<p><strong>NOTE:</strong> The data pool is append only, you cannot edit data in the pool.</p>
</blockquote>

<p>At the beginning of the post, we mentioned Apache Spark and Hadoop, but so far we have only seen SQL Server &ldquo;stuff&rdquo;. Where is Hadoop?</p>

<h4 id="storage-pool">Storage Pool</h4>

<p>In the previous paragraph, we asked where Hadoop comes into the picture, and the answer to that is the storage pool. Let us have a look at one of the pods in the storage pool and see what information we get. We use the same code as for the other pods, and when we execute, we see:</p>

<p><img src="/images/posts/bdc-lap-around-arch-storage-0-containers.png" alt="" /></p>

<p><strong>Figure 12:</strong> <em>Storage Pool &amp; Containers</em></p>

<p>That is interesting! In <em>Figure 12</em> we see the &ldquo;usual suspects&rdquo;; <code>mssql-server</code>, <code>collectd</code>, and <code>fluentbit</code> - but we also see a container we haven&rsquo;t seen before: <code>hadoop</code>.</p>

<p>We have two pods in the storage pool, and the <code>hadoop</code> container in each pod forms part of a Hadoop cluster. The Hadoop container provides persistent storage for unstructured and semi-structured data. Data files, such as Parquet or delimited text, can be stored in the storage pool. Not only is the Hadoop File System, (HDFS), within the container but also Apache Spark:</p>

<p><img src="/images/posts/bdc-lap-around-arch-storage-pool.png" alt="" /></p>

<p><strong>Figure 13:</strong> <em>Storage Pool</em></p>

<p>We have added to our architectural diagram the storage pool cluster as in <em>Figure 13</em>, and at the bottom of the picture, outlined in red, something that looks like files. That represents the ability to mount external HDFS data sources into the storage pool cluster. You access the data via the SQL Server master instance, and PolyBase external tables or you can use the Apache Knox Gateway which sits in the Hadoop name-node: <code>nmnode-0-0</code>, which you see in <em>Figure 4</em>.</p>

<p>You may ask why we have SQL Server instances in the storage pool pods? The Big Data Cluster uses the SQL Servers to optimize the access of the data stored in the HDFS Data Nodes.</p>

<p>We have now looked at the various pools we listed at the beginning of this post, and we should have a relatively good grasp of the architecture of a SQL Server 2019 Big Data Cluster.</p>

<h2 id="applications">Applications</h2>

<p>However, there is one thing more to look at. If we look at <em>Figure 4</em> we see at the very top a pod named <code>appproxy-nsp2m</code>, and its role is <code>proxy</code>. What is this? Well, let us run the same code we have done so many times before and see that containers this pod has:</p>

<p><img src="/images/posts/bdc-lap-around-arch-appproxy-containers.png" alt="" /></p>

<p><strong>Figure 14:</strong> <em>Application Proxy</em></p>

<p>In <em>Figure 14</em> we see that the <code>appproxy-nsp2m</code> has a container named <code>app-service-proxy</code>. This container is used, amongst other things, to enable applications to be deployed to a BDC.</p>

<h4 id="application-pool">Application Pool</h4>

<p>The reason for deploying applications to the BDC is so the applications can benefit from the computational power of the cluster and can access the data that is available on the cluster. Supported runtimes are:</p>

<ul>
<li>R</li>
<li>Python</li>
<li>SSIS</li>
<li>MLeap</li>
</ul>

<p>When we deploy an application to a BDC, it is deployed into the Application Pool:</p>

<p><img src="/images/posts/bdc-lap-around-arch-application-pool.png" alt="" /></p>

<p><strong>Figure 15:</strong> <em>Application Proxy</em></p>

<p>What we see in <em>Figure 15</em> is an example of the application pool where we have a user, outlined in red, interacting with the applications in the pool.</p>

<h2 id="summary">Summary</h2>

<p>This is the second post in a series about SQL Server 2019 Big Data Cluster. In the first post: <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</a> we looked at the reason why SQL Server 2019 Big Data Cluster came about and the tech behind it.</p>

<p>In this post, we looked at the architecture of the BDC. We discussed in this post about:</p>

<ul>
<li>Master Pool: the master instance of SQL Server, which also acts as an entry point into the BDC.</li>
<li>Compute Pool: provides scale-out computational resources for a SQL Server big data cluster.</li>
<li>Data Pool: persistence and caching layer for external data.</li>
<li>Storage Pool: provides persistent storage for unstructured and semi-structured data.</li>
<li>Application Pool: hosts applications running inside the BDC.</li>
</ul>

<p>In future posts, we will look at data virtualization, and how the various pools work.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 50, 2020]]></title>
    <link href="https://nielsberglund.com/2020/12/13/interesting-stuff---week-50-2020/" rel="alternate" type="text/html"/>
    <updated>2020-12-13T09:49:39+02:00</updated>
    <id>https://nielsberglund.com/2020/12/13/interesting-stuff---week-50-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<blockquote>
<p><strong>NOTE:</strong> <em>It is now coming up on Christmas and New Year, and I will take a break with these posts and come back in the beginning of next year.</em></p>
</blockquote>

<p></p>

<h2 id="sql-server-2019-big-data-cluster-bdc">SQL Server 2019 Big Data Cluster (BDC)</h2>

<ul>
<li><a href="https://techcommunity.microsoft.com/t5/sql-server/sql-server-big-data-clusters-cu8-release-surfaces-encryption-at/ba-p/1956946">SQL Server Big Data Clusters CU8 release surfaces Encryption at Rest capabilities and more</a>. The latest cumulative update, (CU8), for SQL Server 2019 BDC includes several fixes, optimizations and adds two main capabilities for SQL Server BDC. This post looks at some of the major improvements, provides additional context to understand the design behind these capabilities better, and points you to relevant resources to learn more and get you started.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/minibooks/chaos-engineering/">The InfoQ eMag - Real World Chaos Engineering</a>. This <a href="https://www.infoq.com/">InfoQ</a> post links to a download of an &ldquo;eMag&rdquo; around chaos engineering. The eMag pulls together a variety of case studies to show mechanisms by which you can implement chaos engineering.</li>
<li><a href="https://www.infoq.com/news/2020/12/grafana-tempo-distributed-tracin/">Grafana Announces Grafana Tempo, a Distributed Tracing System</a>. The <a href="https://www.infoq.com/">InfoQ</a> article linked to here looks at Grafana Tempo, the distributed tracing backend recently released by Grafana Labs. Grafana Tempo integrates with any existing logging system to create links from trace IDs in log lines, and it only requires object storage like Amazon S3 or Google Cloud Storage (GCS) to operate.</li>
</ul>

<h2 id="data">Data</h2>

<ul>
<li><a href="https://www.theseattledataguy.com/how-can-presto-and-starburst-data-improve-your-data-analytics/">How Can Presto And Starburst Data Improve Your Data Analytics</a>. At <a href="/derivco">Derivco</a> we have started looking at Presto. Presto is an open-source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes. This post looks more in detail what Presto is and why companies are using it.</li>
<li><a href="https://towardsdatascience.com/deploying-a-python-sql-engine-to-your-cluster-76a590940977">Mix SQL and Machine Learning and leverage your computation cluster</a>. The post linked to above discussed Presto. This post looks at another distributed SQL query engine - <a href="https://nils-braun.github.io/dask-sql/">dask-sql</a>. In the post, the author examines what dask-sql is and how it can be used in machine learning scenarios. Very cool!</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://medium.com/microsoftazure/no-code-data-enhancement-with-azure-synapse-analytics-and-azure-auto-ml-cb9d97fb0c26">No Code Data Enrichment with Azure Synapse and Azure Machine Learning</a>. This post will walk through how to train and evaluate Azure ML AutoML Regressions model on your data using Azure Synapse Analytics Spark and SQL pools. Quite interesting!</li>
<li><a href="https://www.confluent.io/blog/transactional-machine-learning-with-maads-viper-and-apache-kafka/">Transactional Machine Learning at Scale with MAADS-VIPER and Apache Kafka</a>. The post linked to here shows how transactional machine learning (TML) integrates data streams with automated machine learning (AutoML). Apache Kafka is used as the data backbone, and it allows the creation of a frictionless machine learning process.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.youtube.com/watch?v=KR9yvcNBFIw">Event Streaming Applications with Zero Infrastructure</a>. In this YouTube video, <a href="https://twitter.com/tlberglund">Tim Berglund</a>, (from Confluent), demos how you can quickly spin up new event streaming applications with ksqlDB, Kafka, and connectors, all in a fully managed way on Confluent Cloud.</li>
<li><a href="https://www.confluent.io/blog/kafka-lag-monitoring-and-metrics-at-appsflyer/">Apache Kafka Lag Monitoring at AppsFlyer</a>. One crucial aspect of every distributed system is visibility - how do you see what&rsquo;s going on? In streaming applications, it is vital that we can see if consumers are lagging. The post linked to here looks at how one can implement a system for monitoring lag in Kafka.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 49, 2020]]></title>
    <link href="https://nielsberglund.com/2020/12/06/interesting-stuff---week-49-2020/" rel="alternate" type="text/html"/>
    <updated>2020-12-06T09:06:09+02:00</updated>
    <id>https://nielsberglund.com/2020/12/06/interesting-stuff---week-49-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/news/2020/11/microsoft-releases-dotnet-spark/">Microsoft Releases .NET for Apache Spark 1.0</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article looking at the first major version of .NET for Apache Spark, an open-source package that brings .NET development to the Apache Spark platform. The new release allows .NET developers to write Apache Spark applications using .NET user-defined functions, Spark SQL, and additional libraries such as Microsoft Hyperspace and ML.NET. I can say that the developers here at <a href="/derivco">Derivco</a> are quite excited about this!</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/podcasts/service-mesh-interface/">Michelle Noorali on the Service Mesh Interface Spec and Open Service Mesh Project</a>. The <a href="https://www.infoq.com/">InfoQ</a> podcast linked to here covers quite a few topics: the service mesh interface (SMI) spec, the open service mesh (OSM) project, and the future of application development on Kubernetes.</li>
<li><a href="https://www.infoq.com/articles/microservice-monitoring-right-way/">Monitoring Microservices the Right Way</a>. Another article from <a href="https://www.infoq.com/">InfoQ</a>. The article looks at how recent innovations in open-source time-series databases have improved the scalability of monitoring tools such as Prometheus. These solutions can handle microservices large scale of data while providing metric scraping, querying, and visualization based on Prometheus and Grafana.</li>
<li><a href="https://www.infoq.com/news/2020/12/microservices-strangler-fig/">Migrating a Monolith towards Microservices with the Strangler Fig Pattern</a>. The article linked to here looks at how a company, <a href="https://scholarpack.com">ScholarPack</a>, managed to migrate away from a monolith backend using a Strangler Fig pattern. They applied incremental development and continuous delivery to target customers’ needs, in the meanwhile strangling their monolith. All this is very interesting for us, <a href="/derivco">Derivco</a>!</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://engineering.linkedin.com/blog/2020/open-sourcing-dagli">Dagli: Faster and easier machine learning on the JVM, without the tech debt</a>. This post by the LinkedIn engineering team is about the release of Dagli. Dagli is an open source machine learning library for Java (and other JVM languages) that makes it easy to write bug-resistant, readable, modifiable, maintainable, and trivially deployable model pipelines without incurring technical debt.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/apache-kafka-spring-cloud-data-flow-tutorial/">Getting Started with Spring Cloud Data Flow and Confluent Cloud</a>. This blog post gives you the foundation for event streaming and designing and implementing real-time patterns. Using Confluent Schema Registry, ksqlDB, and fully managed Apache Kafka as a service, you can experience clean, seamless integrations with your existing cloud provider. The post also discusses Spring Cloud Data Flow which is a microservices-based toolkit for building streaming and batch data processing pipelines.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 48, 2020]]></title>
    <link href="https://nielsberglund.com/2020/11/29/interesting-stuff---week-48-2020/" rel="alternate" type="text/html"/>
    <updated>2020-11-29T09:01:28+02:00</updated>
    <id>https://nielsberglund.com/2020/11/29/interesting-stuff---week-48-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/netflix-api-graphql-federation/">How Netflix Scales Its API with GraphQL Federation</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation, where the presenters look at how Netflix uses GraphQL to scale its API&rsquo;s. The usage of GraphQL looks very cool, and maybe we can use it at <a href="/derivco">Derivco</a> as well!</li>
<li><a href="https://medium.com/swlh/the-6-things-you-need-to-know-about-event-driven-architectures-38e11fdcb5a">The 6 Things You Need to Know About Event-Driven Architectures</a>. The post linked to is the second in a series about event driven architectures, (the first is <a href="https://medium.com/swlh/the-engineers-guide-to-event-driven-architectures-benefits-and-challenges-3e96ded8568b">here</a>). In this post, the author looks at, and explains, what in his mind are key concepts of event-driven architectures.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/deploy-machine-learning-applications-to-kubernetes-using-streamlit-and-polyaxon-49bf4b963515">Deploy Machine Learning applications to Kubernetes using Streamlit and Polyaxon</a>. This is a step-by-step guide on how to train, analyze, and deploy a containerized Streamlit machine learning application on Kubernetes using Polyaxon.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://netflixtechblog.com/simple-streaming-telemetry-27447416e68f">Simple streaming telemetry</a>. This post looks at the Netflix <code>gnmi-gateway</code> project. <code>gnmi-gateway</code> is a modular, distributed, and highly available service for modern network telemetry via OpenConfig and gNMI. The <code>gnmi-gateway</code> project looks interesting, and I&rsquo;ll forward the post to our network guys.</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>If you have not signed up for the <a href="https://dataplatformgeeks.com/dps2020/"><strong>Data Platform Virtual Summit 2020</strong></a> yet, you still have some time!</p>

<p>The <strong>Data Platform Virtual Summit 2020</strong>, (DPS), is a 100% technical learning event with 200 Breakout Sessions, 30 Training Classes, 72 hours of non-stop conference sessions.</p>

<p>DPS 2020 is the largest online learning event on Microsoft Azure Data, Analytics &amp; Artificial Intelligence. Delegates get the recordings at no extra cost, which is quite a wonderful thing. Also, the conference virtual platform looks amazing, <a href="https://www.linkedin.com/posts/amitbansal2010_dps2020-sqlserver-powerbi-activity-6728885748755374080-a8QL/">have a look</a>.</p>

<p>You <a href="https://dataplatformgeeks.com/dps2020/booking/">book here</a>. Oh, and since I am a speaker I get a discount code to hand out to you guys! Use the discount code <strong>DPSSPEAKER</strong> to book your seat at <strong>55%</strong> off.</p>

<p>If you wonder what I am speaking about, this should give you an idea:</p>

<p><img src="/images/posts/Niels_Berglund.jpg" alt="" /></p>

<p>In my talk, I will be talking about Kafka and SQL Server, and various ways we can &ldquo;set our SQL Server data free&rdquo;!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 47, 2020]]></title>
    <link href="https://nielsberglund.com/2020/11/22/interesting-stuff---week-47-2020/" rel="alternate" type="text/html"/>
    <updated>2020-11-22T08:52:30+02:00</updated>
    <id>https://nielsberglund.com/2020/11/22/interesting-stuff---week-47-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="azure-data-studio">Azure Data Studio</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2020/11/16/building-and-sharing-jupyter-books-in-azure-data-studio/">Building and sharing Jupyter Books in Azure Data Studio</a>. We all should know by now that Azure Data Studio allows us to use Jupyter notebooks. This post looks at how we can not only use Jupyter books but also create and share them. Very cool!</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://medium.com/expedia-group-tech/autoscaling-in-kubernetes-a-primer-on-autoscaling-7b8f0f95a928">Autoscaling in Kubernetes: A Primer on Autoscaling</a>. This post is the first in a series looking at application autoscaling in Kubernetes. I was going to write that I really look forward to the second instalment when I realized it already had been <a href="https://medium.com/expedia-group-tech/autoscaling-in-kubernetes-options-features-and-use-cases-c8a6ce145957">published</a>! Awesome!</li>
<li><a href="https://martin.kleppmann.com/2020/11/18/distributed-systems-and-elliptic-curves.html">New courses on distributed systems and elliptic curve cryptography</a>. As the title says; Martin Kleppman of <a href="http://dataintensive.net/">Designing Data-Intensive Applications</a> fame have released some new training courses. I am very interested in the distributed systems course; the videos look awesome! This course is a must for anyone interested in distributed systems!</li>
<li><a href="https://medium.com/swlh/distributed-systems-and-asynchronous-i-o-ef0f27655ce5">Distributed Systems and Asynchronous I/O</a>. The post linked to here looks at how different forms of handling I/O affect the performance, availability, and fault-tolerance of network applications.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://medium.com/@dt_23597/if-youre-using-kafka-with-your-microservices-you-re-probably-handling-retries-wrong-8492890899fa">If You’re Using Kafka With Your Microservices, You’re Probably Handling Retries Wrong</a>. In this excellent article, the author looks at various ways of handling retries in Kafka. The article presents a potential solution together with the downsides of that particular solution. As I said in the beginning - this is an excellent article!</li>
<li><a href="https://www.confluent.io/blog/how-real-time-stream-processing-safely-scales-with-ksqldb/">How Real-Time Stream Processing Safely Scales with ksqlDB, Animated</a>. This post is the third in a series around ksqlDB and how it executes stateless and stateful operations. The two previous posts have looked at a single server setup. This post looks at how stateless and stateful operations work when ksqlDB is deployed with many servers, and more importantly, how it linearly scales the work it is performing—even in the presence of faults.</li>
<li><a href="https://www.confluent.io/blog/using-kafka-ksqldb-kibana-to-stream-data-and-get-real-time-analytics/">Analysing historical and live data with ksqlDB and Elastic Cloud</a>. This is a great post by <a href="https://twitter.com/rmoff">Robin Moffat</a>. He looks at how you can take &ldquo;messy and imperfect&rdquo; data, (think CSV), from a &ldquo;raw data&rdquo; Kafka topic, re-format it, and make it presentable with ksqlDB, push it into another topic, and from there stream it into an analytical dashboard. Awesome stuff!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>Don&rsquo;t forget Data Platform Summit 2020.</p>

<p><img src="/images/posts/dps_2020.png" alt="" /></p>

<p>I am super excited to be speaking at the <a href="https://dataplatformgeeks.com/dps2020/"><strong>Data Platform Virtual Summit 2020</strong></a>:</p>

<p><img src="/images/posts/Niels_Berglund.jpg" alt="" /></p>

<p>and as you see in the figure above, my presentation is about Kafka and SQL Server.</p>

<p>The <strong>Data Platform Virtual Summit 2020</strong>, (DPS), is a 100% technical learning event with 200 Breakout Sessions, 30 Training Classes, 72 hours of non-stop conference sessions. DPS 2020 is the largest online learning event on Microsoft Azure Data, Analytics &amp; Artificial Intelligence. Delegates get the recordings at no extra cost, which is quite a wonderful thing. Also, the conference virtual platform looks amazing, <a href="https://www.linkedin.com/posts/amitbansal2010_dps2020-sqlserver-powerbi-activity-6728885748755374080-a8QL/">take a look</a>.</p>

<p>If you want to attend and hear industry experts talk about really exciting stuff you can <a href="https://dataplatformgeeks.com/dps2020/booking/">book here</a>. Oh, and the coolest thing is that as I am a speaker I get a discount code to hand out to you guys! Use the discount code <strong>DPSSPEAKER</strong> to book your seat at <strong>55%</strong> off.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 46, 2020]]></title>
    <link href="https://nielsberglund.com/2020/11/15/interesting-stuff---week-46-2020/" rel="alternate" type="text/html"/>
    <updated>2020-11-15T09:31:21+02:00</updated>
    <id>https://nielsberglund.com/2020/11/15/interesting-stuff---week-46-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="misc">Misc.</h2>

<ul>
<li><a href="https://towardsdatascience.com/how-to-integrate-python-and-r-in-visual-studio-code-496a47c90422">How to integrate Python and R in Visual Studio Code</a>. I really like VSCode, but I always have issues with how to configure for Python and R when installing from scratch. So this blog-post comes in real handy, as it explains what one needs to do to get Python and R up and running in VSCode. Awesome!</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/synthetic-data-vault-sdv-a-python-library-for-dataset-modeling-b48c406e7398">Synthetic Data Vault (SDV): A Python Library for Dataset Modeling</a>. When doing machine learning/data science, you need realistic data to work with, and that can sometimes be a problem. This post introduces the Synthetic Data Vault, which is a tool to generate complex datasets using statistical &amp; machine-learning models. It looks very interesting!</li>
<li><a href="https://eng.uber.com/metadata-insights-databook/">Turning Metadata Into Insights with Databook</a>. This post looks at Uber&rsquo;s system for handling metadata - Databook.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://medium.com/apache-pinot-developer-blog/using-apache-pinot-and-kafka-to-analyze-github-events-93cdcb57d5f7">Using Apache Pinot and Kafka to Analyze GitHub Events</a>. Apache Pinot is a real-time distributed OLAP datastore, which is used to deliver scalable real-time analytics with low latency. The post I linked to here discusses how to ingest Kafka events into Pinot. What we see in the blog post is very interesting for <a href="/derivco">us</a>, and we will definitely look at it in more detail.</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>In <a href="/2020/11/08/interesting-stuff---week-45-2020/">last weeks roundup</a> I wrote about my recording of video for the Data Platform Summit 2020.</p>

<p><img src="/images/posts/dps_2020.png" alt="" /></p>

<p>If I haven&rsquo;t said it before:</p>

<p>I am super excited to be speaking at the <a href="https://dataplatformgeeks.com/dps2020/"><strong>Data Platform Virtual Summit 2020</strong></a>. A 100% technical learning event with 200 Breakout Sessions, 30 Training Classes, 72 hours of non-stop conference sessions – DPS 2020 is the largest online learning event on Microsoft Azure Data, Analytics &amp; Artificial Intelligence. Delegates get the recordings at no extra cost, which is quite a wonderful thing. Also, the conference virtual platform looks amazing, <a href="https://www.linkedin.com/posts/amitbansal2010_dps2020-sqlserver-powerbi-activity-6728885748755374080-a8QL/">take a look</a>.</p>

<p>If you want to attend and hear industry experts talk about really exciting stuff you can <a href="https://dataplatformgeeks.com/dps2020/booking/">book here</a>. Oh, and the coolest thing is that as I am a speaker I get a discount code to hand out to you guys! Use the discount code <strong>DPSSPEAKER</strong> to book your seat at <strong>55%</strong> off.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 45, 2020]]></title>
    <link href="https://nielsberglund.com/2020/11/08/interesting-stuff---week-45-2020/" rel="alternate" type="text/html"/>
    <updated>2020-11-08T10:32:09+02:00</updated>
    <id>https://nielsberglund.com/2020/11/08/interesting-stuff---week-45-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="big-data">Big Data</h2>

<ul>
<li><a href="https://blog.acolyer.org/2020/11/02/helios-part-ii/">Helios: hyperscale indexing for the cloud &amp; edge (part II)</a>. In last weeks <a href="/2020/11/01/interesting-stuff---week-44-2020/">roundup</a>, I pointed to a post by <a href="https://twitter.com/adriancolyer">Adrian</a>, where he dissected a white-paper about Helios, and I said how I looked forward to part 2. Well, I got what I wanted, and the post I link to here is the follow-up. Enjoy!</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://vlfig.me/posts/microservices">Microservices — architecture nihilism in minimalism&rsquo;s clothes</a>. This post looks at microservices and argues that there is no such thing as a microservice architecture, but software architecture. The author also looks at the size of a microservice and argues that there is no prescribed size of a microservice. I found the post very interesting!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://itnext.io/change-data-capture-with-azure-postgresql-and-kafka-4598dbf0b57a">Change Data Capture with Azure, PostgreSQL, and Kafka</a>. In this blog post, the author looks at how one can use Change Data Capture to stream database modifications from PostgreSQL to Azure Data Explorer, (Kusto), using Apache Kafka. It is an interesting post! As a side note, I must say that Azure Data Explorer looks really interesting!</li>
<li><a href="https://www.confluent.io/blog/pull-queries-in-preview-confluent-cloud-ksqdb/">Announcing Pull Queries in Preview in Confluent Cloud ksqlDB</a>. ksqlDB has two types of queries: push and pull. Push queries allow you subscribe to a query&rsquo;s result as it changes in real-time, whereas with a pull query you fetch the current state of a materialized view. Both types of queries have been in Confluent Platform for a while, but Confluent Cloud has up until now only supported push queries. That changes now, and the post I linked to here discusses more in detail about the support for pull queries in Confluent Cloud.</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>Well, it is not so much about what I am doing, as it is of what I have been doing the last couple of days. You who read my blog are probably aware that:</p>

<p><img src="/images/posts/Niels_Berglund.jpg" alt="" /></p>

<p><strong>Figure 1:</strong> <em>SQL Server &amp; Kafka</em></p>

<p>Yes, I am speaking at the conference! My topic is about, as you can see in <em>Figure 1</em>, the various ways we can stream data from SQL Server to Apache Kafka. In a previous roundup, I wrote how I was prepping for the talk. That is all good and well, but a while ago a &ldquo;curve-ball&rdquo; was thrown: the conference is obviously virtual, but: we are not presenting live! Which means that the last few days, I have been recording, and editing the recording. Geez, recording and editing is hard work, compared to &ldquo;just&rdquo; deliver. Well, it is done now, and if you <a href="https://dataplatformgeeks.com/dps2020/booking/https://dataplatformgeeks.com/dps2020/booking/">register</a> you have the chance to see other speakers and me in a recorded fashion.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 44, 2020]]></title>
    <link href="https://nielsberglund.com/2020/11/01/interesting-stuff---week-44-2020/" rel="alternate" type="text/html"/>
    <updated>2020-11-01T11:01:29+02:00</updated>
    <id>https://nielsberglund.com/2020/11/01/interesting-stuff---week-44-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="big-data">Big Data</h2>

<ul>
<li><a href="https://blog.acolyer.org/2020/10/26/helios-part-1/">Helios: hyperscale indexing for the cloud &amp; edge – part 1</a>. In this post <a href="https://twitter.com/adriancolyer">Adrian</a> from the <a href="https://blog.acolyer.org">morning paper</a> dissects a white-paper about Helios. Helios is a distributed, highly-scalable system used at Microsoft for flexible ingestion, indexing, and aggregation of large streams of real-time data that is designed to plug into relational engines. Adrian is as thorough as usual, and the conclusions he draws are very interesting. I can&rsquo;t wait for part 2.</li>
</ul>

<h2 id="distributed-systems">Distributed Systems</h2>

<ul>
<li><a href="https://medium.com/@polyglot_factotum/how-i-am-learning-distributed-systems-7eb69b4b51bd">How I am learning distributed systems</a>. This post looks, from one person&rsquo;s perspective, how one can learn to design distributed systems. What is interesting in this post is the use of <a href="https://raft.github.io/">Raft</a>, (no, not Raft the game - but the consensus algorithm), as a learning tool. I will definitely point to this post as a learning resource for my developers.</li>
<li><a href="https://thenewstack.io/nginx-steps-into-the-service-mesh-fray-promising-a-simpler-alternative/">NGINX Steps into the Service Mesh Fray Promising a Simpler Alternative</a>. The post linked to here points discusses how NGINX introduces its own service mesh: <a href="https://www.nginx.com/products/nginx-service-mesh">NGINX Service Mesh</a>, (NSM). It promises to be less complicated than ISTIO, so I will definitely have a look.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/how-to-prepare-for-kip-500-kafka-zookeeper-removal-guide/">Preparing Your Clients and Tools for KIP-500: ZooKeeper Removal from Apache Kafka</a>. The Kafka community has for quite a while been talking about removing the dependency of ZooKeeper, (ZK), from Kafka, and it seems we are getting closer. In the post I have linked to here, the author looks at what is needed to do in Kafka consumers so that nothing &ldquo;bad&rdquo; happens when ZK is eventually removed.</li>
<li><a href="https://www.kai-waehner.de/blog/2020/10/27/streaming-machine-learning-kafka-native-model-server-deployment-rpc-embedded-streams/">Streaming Machine Learning with Kafka-native Model Deployment</a>. Kafka is used more and more for real-time machine learning purposes, and we are moving towards Kafka as a native streaming model server. This blog post explores the architectures and trade-offs between various options for model deployment with Kafka.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 43, 2020]]></title>
    <link href="https://nielsberglund.com/2020/10/25/interesting-stuff---week-43-2020/" rel="alternate" type="text/html"/>
    <updated>2020-10-25T09:35:38+02:00</updated>
    <id>https://nielsberglund.com/2020/10/25/interesting-stuff---week-43-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/news/2020/10/kubernetes-chaos-mesh-ga/">Chaos Engineering on Kubernetes : Chaos Mesh Generally Available with v1.0</a>. In <a href="/2020/10/18/interesting-stuff---week-42-2020/">last weeks roundup</a>, I wrote about Kraken, a chaos tool for OpenShift/Kubernetes. This week and in this <a href="https://www.infoq.com/">InfoQ</a> article, we look at another chaos tool; Chaos Mesh.</li>
</ul>

<h2 id="big-data-analytics">Big Data Analytics</h2>

<ul>
<li><a href="https://eng.uber.com/operating-apache-pinot/">Operating Apache Pinot @ Uber Scale</a>. Apache Pinot is a distributed OLAP system designed for performing low latency analytical queries on really Big Data. The post linked to here looks at how Uber is using Pinot, and how the underlying architecture looks like.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/real-time-risk-management-with-kafka-and-event-streaming/">Lessons Learned from Evolving a Risk Management Platform to Event Streaming</a>. This post looks at how a retailer uses Kafka and event streaming to perform risk management. Very cool!</li>
<li><a href="https://netflixtechblog.com/building-netflixs-distributed-tracing-infrastructure-bb856c319304">Building Netflix’s Distributed Tracing Infrastructure</a>. This post looks at the underlying architecture/components for Netflix tracing framework <a href="https://netflixtechblog.com/edgar-solving-mysteries-faster-with-observability-e1a76302c71f">Edgar</a>. It is a very interesting and informative post! Let us see if we can do something similar at <a href="/derivco">Derivco</a>.</li>
<li><a href="https://www.confluent.io/blog/bounding-ksqldb-memory-usage/">Bounding ksqlDB Memory Usage</a>. This post which looks at how one can solve unbounded ksqlDB memory growth comes at the right time for us at <a href="/derivco">Derivco</a>, as we have experienced this problem in ksqlDB.</li>
<li><a href="https://www.confluent.io/blog/build-a-intrusion-detection-using-ksqldb/">Intrusion Detection with ksqlDB</a>. We know that ksqlDB can be used for many things and the post linked to here looks at how to use ksqlDB to detect network intrusions. Really, really cool!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 42, 2020]]></title>
    <link href="https://nielsberglund.com/2020/10/18/interesting-stuff---week-42-2020/" rel="alternate" type="text/html"/>
    <updated>2020-10-18T08:55:21+02:00</updated>
    <id>https://nielsberglund.com/2020/10/18/interesting-stuff---week-42-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>Kafka, Kafka, and Kafka</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.openshift.com/blog/introduction-to-kraken-a-chaos-tool-for-openshift/kubernetes">Introduction to Kraken, a Chaos Tool for OpenShift/Kubernetes</a>. As the title of this post says, it introduces a Kubernetes tool which by you can chaos test your Kubernetes cluster. It looks quite interesting and useful, and I have forwarded the post to the guys at <a href="/derivco">Derivco</a> looking at Kubernetes.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.fullcontact.com/blog/2020/10/08/building-a-lambda-architecture-with-druid-and-kafka-streams/">Building a Lambda Architecture with Druid and Kafka Streams</a>. The post linked to here looks at how to use <a href="https://druid.apache.org/">Druid</a> together with KStreams to build a real-time analytical framework. Really interesting &ldquo;stuff&rdquo;!</li>
<li><a href="https://www.confluent.io/blog/how-real-time-materialized-views-work-with-ksqldb/">How Real-Time Materialized Views Work with ksqlDB, Animated</a>. The post delivers precisely what the title says: it looks at how materialized views work in ksqlDB. I really like the animations in the post, very cool!</li>
<li><a href="https://www.infoq.com/articles/real-time-api-kafka/">Real Time APIs in the Context of Apache Kafka</a>. This <a href="https://www.infoq.com/">InfoQ</a> article by the Kafka Guru <a href="https://twitter.com/rmoff">Robin Moffat</a> looks at how events together with real-time APIs can be used as the foundation for applications which are flexible yet performant; loosely-coupled yet efficient. Apache Kafka offers a scalable event streaming platform with which you can build applications around the powerful concept of events.<br /></li>
<li><a href="https://www.confluent.io/blog/5-things-every-kafka-developer-should-know/">Top 5 Things Every Kafka Developer Should Know</a>. I believe that a developer, to be a good developer, should have an in-depth knowledge of the technologies he/she is working with. If you are using Kafka, then the post linked to here gives you a good start in understanding Kafka.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 41, 2020]]></title>
    <link href="https://nielsberglund.com/2020/10/11/interesting-stuff---week-41-2020/" rel="alternate" type="text/html"/>
    <updated>2020-10-11T08:57:28+02:00</updated>
    <id>https://nielsberglund.com/2020/10/11/interesting-stuff---week-41-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="sql-server-2019-big-data-cluster">SQL Server 2019 Big Data Cluster</h2>

<ul>
<li><a href="https://mohammaddarab.com/stop-and-start-your-aks-big-data-cluster-and-save-money/">Stop and Start your AKS Big Data Cluster and Save $$$</a>. In this post, my good friend <a href="https://twitter.com/mwdarab">Mohammad</a> looks at new functionality in Azure Kubernetes Service, (AKS), whereby you can start and stop Kubernetes clusters at will. Mohammad looks at it from the perspective of SQL Server 2019 Big Data Clusters running in AKS.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://medium.com/data-rocks/kafka-record-tracing-379ed2b0af51">Kafka record tracing</a>. Do you know how long it takes for messages to flow in your data pipeline? Do you know where the bottlenecks are? Why I ask these questions is that in a distributed system, the answers may not always be that easy to find. The post linked to here looks at solutions to these questions, and it looks at distributed tracing for Kafka.</li>
<li><a href="https://www.confluent.io/blog/kafka-cluster-linking-with-confluent-platform/">Introducing Cluster Linking in Confluent Platform 6.0</a>. As the title of this post says, the post is about linking Kafka clusters to each other. From the post: &ldquo;Replicating topics between Kafka clusters has been a long-standing problem that’s seen a number of solutions, including MirrorMaker and Confluent Replicator. Although the utility of these projects has come a long way, they’re not without their respective issues.&rdquo;. The issues referred to in the previous sentence, is what the new cluster linking functionality is supposed to fix. It looks very promising, the one question I have right now is if this is a Confluent Platform Enterprise only functionality?</li>
<li><a href="https://medium.com/data-rocks/managing-kafka-connectors-at-scale-using-kafka-connect-manager-kcm-31d887de033c">Managing Kafka Connectors at scale using Kafka Connect Manager</a>. A while back we, (<a href="/derivco">Derivco</a>), looked at using CDC and Debezium to get data out from the database to Kafka. One of the problems we faced was how to manage the various Kafka Connectors, and ensure they were functioning correctly. The post I link to here would have been the perfect solution for us - a framework for managing Kafka Connectors. It would be interesting to know if it is open-sourced.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 40, 2020]]></title>
    <link href="https://nielsberglund.com/2020/10/04/interesting-stuff---week-40-2020/" rel="alternate" type="text/html"/>
    <updated>2020-10-04T15:40:24+02:00</updated>
    <id>https://nielsberglund.com/2020/10/04/interesting-stuff---week-40-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="big-data">Big Data</h2>

<ul>
<li><a href="https://databricks.com/blog/2020/09/29/diving-into-delta-lake-dml-internals-update-delete-merge.html">Diving Into Delta Lake: DML Internals (Update, Delete, Merge)</a>. Later releases of Delta Lake supports DML, (data manipulation language), statements. The post linked to here demonstrates how to use each of these DML commands, describes what Delta Lake is doing behind the scenes when you run one, and offers some performance tuning tips for each one. Very cool!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/confluent-platform-6-0-delivers-the-most-powerful-event-streaming-platform-to-date/">Introducing Confluent Platform 6.0</a>. As the title of this post says; the post is about the new 6.0 release of Confluent Platform. Reading the post, this release looks huge. There are so many interesting things in there, but the ones that stand out for me are the ksqlDB improvements! For more information about the new ksqlDB functionality, look at the post <a href="https://www.confluent.io/blog/ksqldb-0-12-0-features-updates/">ksqlDB 0.12.0 Introduces Real-Time Query Upgrades and Automatic Query Restarts</a>. This is awesome!</li>
<li><a href="https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">How Real-Time Stream Processing Works with ksqlDB, Animated</a>. While we are on the subject of ksqlDB, this post is doing a great job how ksqlDB works. If you are interested in ksqlDB at all, you must read the post!</li>
<li><a href="https://www.confluent.io/blog/ksqldb-java-client-iot-inspired-demo/">ksqlDB Meets Java: An IoT-Inspired Demo of the Java Client for ksqlDB</a>. Even more ksqlDB. The post linked to here looks at the new ksqlDB Java client. So, instead of using REST API&rsquo;s, you can now do ksqlDB &ldquo;stuff&rdquo; programmatically, using this new client, That is very, very interesting!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>Yes, what AM I doing? Sometimes, quite often actually, I wonder that myself. Today, however, I do know what I am doing, or more specifically, what I just did! Yesterday, (October 3), I delivered a virtual conference talk at SQLBits about SQL Server and Kafka.</p>

<p>Unfortunately, the talk was pre-recorded, and after I had uploaded the recording, the organizers did some editing. I messed up with what parts of the talk needed editing, so the result was that around a third of the talk was missing. Not good! Anyway, the organizers will do a re-edit and upload so that attendees can view it on demand. If you were one of the attendees, I do apologize again!</p>

<p>Anyway, today I uploaded the slide deck as well as all code for the talk, (including instructions). If you are interested, you can download it from <a href="https://nielsberglund.com/download/set-data-free-kafka.zip">here</a>. If you have questions comments etc., please <a href="mailto:niels.it.berglund@gmail.com">ping me</a>.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 39, 2020]]></title>
    <link href="https://nielsberglund.com/2020/09/27/interesting-stuff---week-39-2020/" rel="alternate" type="text/html"/>
    <updated>2020-09-27T09:41:44+02:00</updated>
    <id>https://nielsberglund.com/2020/09/27/interesting-stuff---week-39-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/monzo-microservices/">Modern Banking in 1500 Microservices</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation where the presenters explain how <a href="https://en.wikipedia.org/wiki/Monzo_(bank)">Monzo</a> builds, operates, observes and maintains the banking infrastructure. They talk about how they compose microservices to add new functionality, deployment and incident tooling, monitoring practices and how they share knowledge effectively. Very interesting!</li>
<li><a href="https://www.infoq.com/podcasts/urban-planning-software-architecture/">Pat Helland on Software Architecture and Urban Planning</a>. The link here is to a podcast by the legendary <a href="https://www.linkedin.com/in/pathelland/">Pat Helland</a> where he talks about the relationship between software architecture and urban planning. Pat explores planning for future growth, regulations/standards, and communication practices that cities - and software architecture - had to evolve to use. He uses these comparisons to distil lessons that architects can use in building distributed systems. If you are only going to listen to one podcast today, this week, month, etc., listen to this one!</li>
</ul>

<h2 id="azure-data-studio">Azure Data Studio</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2020/09/22/the-september-2020-release-of-azure-data-studio-is-now-available/">The September 2020 release of Azure Data Studio is now available</a>. As the title of the post says: a new version of Azure Data Studio is out. It has quite a few new features and enhancements, new notebook functionality, support for Kusto Query Language, (KQL), and other stuff. After I have published this post I will download this version and take it through its paces.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2020/09/24/open-sourcing-the-r-and-python-language-extensions-for-sql-server/">Open sourcing the R and Python language extensions for SQL Server</a>. Wow, this is big! Not only have the SQL Server language extensions for R and Python been open-sourced, but you can now use whatever version of R and Python you want, (well, more or less). Look out for some blog posts from me around this. Here are two links if you are interested in how it worked up until now: <a href="https://nielsberglund.com/categories/sql-server-machine-learning-services/">Sql Server Machine Learning Services</a>, and <a href="https://nielsberglund.com/categories/sql-server-extensibility-framework/">Sql Server Extensibility Framework</a>.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-devops-with-confluent-kubernetes-and-gitops/">Apache Kafka DevOps with Kubernetes and GitOps</a>. The post linked to here looks at how we can do DevOps with Kafka and Kubernetes.</li>
<li><a href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2020/streaming-logging-pipeline-of-home-timeline-prediction-system.html">Streaming logging pipeline of Home timeline prediction system</a>. Twitter recently built a streaming data logging pipeline for its home timeline prediction system using Apache Kafka and Kafka Streams to replace the existing offline batch pipeline. This post looks at the architecture and how Twitter did it. In the post, it is mentioned that Twitter had to customise how KStreams left join semantic, and that is covered in the post: <a href="https://www.confluent.io/blog/how-twitter-built-a-machine-learning-pipeline-with-kafka/">Building a Machine Learning Logging Pipeline with Kafka Streams at Twitter</a>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 38, 2020]]></title>
    <link href="https://nielsberglund.com/2020/09/20/interesting-stuff---week-38-2020/" rel="alternate" type="text/html"/>
    <updated>2020-09-20T08:19:16+02:00</updated>
    <id>https://nielsberglund.com/2020/09/20/interesting-stuff---week-38-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="azure-sql-server">Azure SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2020/09/17/azure-sql-digital-event-transform-your-applications-with-azure-sql/">Azure SQL digital event: Transform your applications with Azure SQL</a>. This post announces a webinar by <a href="https://twitter.com/bobwardms">Bob Ward</a> about Azure SQL, and how you can get the most out of Azure SQL. As the post says: &ldquo;<em>During this hour-long virtual event, I&rsquo;ll share my advice and guidance on getting the most out of Azure SQL, whether you’re looking to migrate from an on-premises SQL Server deployment or exploring ways to utilize the newest Azure SQL service options. You will also hear firsthand experiences and best practices from customers who have become expert Azure SQL users.</em>&rdquo;. Bob is a legend in the SQL Server world, so if you are interested, hurry up and register!</li>
</ul>

<h2 id="big-data">Big Data</h2>

<ul>
<li><a href="https://medium.com/superawesome-engineering/how-we-use-apache-druids-real-time-analytics-to-power-kidtech-at-superawesome-8da6a0fb28b1">How we use Apache Druid’s real-time analytics to power kidtech at SuperAwesome</a>. This post looks at real-time analytics of big data using Kafka and Apache Druid. I like the post a lot!</li>
<li><a href="https://databricks.com/blog/2020/09/15/easily-clone-your-delta-lake-for-testing-sharing-and-ml-reproducibility.html">Easily Clone your Delta Lake for Testing, Sharing, and ML Reproducibility</a>. The post linked to here introduces new functionality in Databricks Delta Lake; the ability to clone tables. This can come in handy for several scenarios: ML result reproducibility, data migration, significant changes to production tables, etc.</li>
</ul>

<h2 id="event-driven-architecture">Event Driven Architecture</h2>

<ul>
<li><a href="https://www.infoq.com/articles/event-driven-finding-seams/">From Monolith to Event-Driven: Finding Seams in Your Future Architecture</a>. An excellent <a href="https://www.infoq.com/">InfoQ</a> article looking at what we can do when we want to migrate from a monolithic architecture to a microservices/domain driven architecture.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://medium.com/faun/event-driven-autoscaling-for-kubernetes-with-kafka-keda-d68490200812">Event-driven Autoscaling for Kubernetes with Kafka &amp; Keda</a>. A very cool post looking at how to scale Kafka consumers on Kubernetes. As I said, very cool!</li>
<li><a href="https://www.confluent.io/blog/stream-data-from-kafka-to-azure-data-explorer/">Streaming Data from Apache Kafka into Azure Data Explorer with Kafka Connect</a>. This blog post shows how to stream events from Apache Kafka on Confluent Cloud on Azure, into Azure Data Explorer, using the Kafka Connect Kusto Sink Connector.</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>I am prepping for one of the largest data platform conferences taking place, (virtually), beginning of December this year: <a href="https://dataplatformgeeks.com/dps2020/"><strong>DATA PLATFORM VIRTUAL SUMMIT 2020</strong></a>. I hear you asking: &ldquo;why are you prepping?&rdquo;. Well, that&rsquo;s because:</p>

<p><img src="/images/posts/Niels_Berglund.jpg" alt="" /></p>

<p><strong>Figure 1:</strong> <em>SQL Server &amp; Kafka</em></p>

<p>Yes, I am speaking at the conference! My topic is about, as you can see in <em>Figure 1</em>, the various ways we can stream data from SQL Server to Apache Kafka.</p>

<p>The conference has world class-speakers, (and me), so hurry up and <a href="https://dataplatformgeeks.com/dps2020/booking/">register</a>!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 37, 2020]]></title>
    <link href="https://nielsberglund.com/2020/09/13/interesting-stuff---week-37-2020/" rel="alternate" type="text/html"/>
    <updated>2020-09-13T09:38:45+02:00</updated>
    <id>https://nielsberglund.com/2020/09/13/interesting-stuff---week-37-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/distributed-video-sharing-demo/">Distributed Programming, Hash Tables, and Fun!</a>. In this <a href="https://www.infoq.com/">InfoQ</a> presentation, the presenters demonstrate how they built a distributed hash-table video-sharing system, the technical hurdles encountered, and the pros/cons of using functional languages to do so. Very interesting!</li>
</ul>

<h2 id="machine-learning">Machine Learning</h2>

<ul>
<li><a href="https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463">Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning &amp; Big Data</a>. Cheat sheets are good, and I certainly need them. The post linked to gives, according to the post, <em>the most complete list of best AI cheat sheets</em>. I don&rsquo;t know about that, but there are some quite cool cheat sheets in there.</li>
<li><a href="https://dalelane.co.uk/blog/?p=4124">Using TensorFlow to make predictions from Kafka events</a>. This is a very interesting post, looking at how you can use Kafka and TensorFlow together to make machine learning predictions around sensor events.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/prioritize-messages-in-kafka/">Implementing Message Prioritization in Apache Kafka</a>. This post came at the exact right time, as I have been battling with how to implement priority messages in Kafka. In Rabbit, which we used previously, it was easy. In Kafka not so much. So reading about &ldquo;bucketing&rdquo; saved the day!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>In <a href="/2020/09/06/interesting-stuff---week-36-2020/">last weeks roundup</a> I said how I was going to do a <strong>Derivco Webinar</strong> this week about <strong>SQL Server 2019 Big Data Cluster</strong>. Well, I did it September 10, it went off without a &ldquo;hitch&rdquo;, and - if I can say it myself - it was a lot of fun. If you are interested in seeing it, you find it on the Derivco YouTube channel <a href="https://www.youtube.com/watch?v=EyCsQP5VJhU">here</a>.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 36, 2020]]></title>
    <link href="https://nielsberglund.com/2020/09/06/interesting-stuff---week-36-2020/" rel="alternate" type="text/html"/>
    <updated>2020-09-06T08:40:13+02:00</updated>
    <id>https://nielsberglund.com/2020/09/06/interesting-stuff---week-36-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://medium.com/@madslundt/microservices-with-event-sourcing-using-net-core-33e3074171f5">Microservices with event sourcing using .NET Core</a>. This post looks at how to implement and structure an API using microservices and event sourcing. The article is very interesting, and it definitely gives &ldquo;food for thought&rdquo;!</li>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-the-half-type/">Introducing the Half type!</a>. The title of the post says it all. Microsoft introduces a new type in .NET 5 - the <code>Half</code> type, which is <code>binary16</code>. The reason for this is that many computation workloads already take advantage of the <code>Half</code> type: machine learning, graphics cards, etc.</li>
</ul>

<h2 id="big-data">Big Data</h2>

<ul>
<li><a href="https://medium.com/oreillymedia/introducing-presto-839a26aac724">Introducing Presto</a>. Presto is a distributed SQL query engine, and it is designed to efficiently query data against disparate data sources of all sizes, ranging from gigabytes to petabytes. This post introduces Presto and looks at how Presto works. I find Presto very interesting in that we can use Presto to query Kafka!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/testing-kafka-applications/">Creating a Serverless Environment for Testing Your Apache Kafka Applications</a>. This post looks at how to use the <code>ccloud-stack</code> utility to create a serverless Kafka environment and how to use the Confluent Cloud CLI to provision a fully managed Datagen connector to pre-populate Kafka topics for your applications to use. Stay tuned for a blog-post from me where I test this out!</li>
<li><a href="https://www.confluent.io/blog/confluent-cloud-enables-event-driven-architectures-everywhere-in-azure/">Enabling the Deployment of Event-Driven Architectures Everywhere Using Microsoft Azure and Confluent Cloud</a>. It becomes more and more common that we operate in a hybrid on-prem -&gt; cloud environment. Data migration can be a complex process. This post looks at how to build a persistent bridge from on-premises or other clouds to Microsoft Azure using Confluent Replicator.</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>Back in May I did together with <a href="https://charlla.com/">Charl</a> a <a href="/derivco">Derivco</a> webinar around <a href="https://www.youtube.com/watch?v=CSyNiEgEyvY">Kafka</a>. This coming week, (Thursday, Sep. 10), I am doing another webinar - this time about SQL Server 2019 Big Data Cluster. The webinar is open to everyone, and you can sign up <a href="https://derivco.co.za/derivco-webinar-a-lap-around-sql/">here</a>.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 35, 2020]]></title>
    <link href="https://nielsberglund.com/2020/08/30/interesting-stuff---week-35-2020/" rel="alternate" type="text/html"/>
    <updated>2020-08-30T09:45:18+02:00</updated>
    <id>https://nielsberglund.com/2020/08/30/interesting-stuff---week-35-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://techcommunity.microsoft.com/t5/azure-sql-database/what-is-azure-sql-edge-data-exposed/ba-p/1614877">What is Azure SQL Edge | Data Exposed</a>. This is part one of a three-part video series about Azure SQL Edge. In this part, we get an introduction to Azure SQL Edge and its features.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://databricks.com/blog/2020/08/27/enabling-spark-sql-ddl-and-dml-in-delta-lake-on-apache-spark-3-0.html">Enabling Spark SQL DDL and DML in Delta Lake on Apache Spark 3.0</a>. This post, and video, discuss some of the cool new features in Delta Lake 0.7.0. There are quite a lot of new exciting things in that release!</li>
<li><a href="https://www.confluent.io/blog/kafka-summit-2020-session-highlights/">Best of Kafka Summit 2020 Roundup</a>. So, The Kafka Summit took place August 24 - 25, (virtually), and I managed to attend quite a few sessions. The post linked to here lists some of the &ldquo;must-see&rdquo; sessions. For me, the best session was the keynote the second day by Jay Kreps and Sam Newman. It was awesome!</li>
<li><a href="https://lenses.io/resources/streaming-sql-cheat-sheet-for-apache-kafka/">Streaming SQL Cheat Sheet for Apache Kafka</a>. As the title says, link to a cheat sheet for ksqlDB syntax. I have downloaded the cheat sheet and have it on my desktop so that I can access it easy!</li>
<li><a href="https://www.kafka-streams-book.com/">Mastering Kafka Streams and ksqlDB</a>. The book in the post linked to here promises to be the &ldquo;go-to&rdquo; book for anything KStreams/ksqlDB related. I&rsquo;ll make sure my developers get some copies!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 34, 2020]]></title>
    <link href="https://nielsberglund.com/2020/08/23/interesting-stuff---week-34-2020/" rel="alternate" type="text/html"/>
    <updated>2020-08-23T11:47:46+02:00</updated>
    <id>https://nielsberglund.com/2020/08/23/interesting-stuff---week-34-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="misc">Misc.</h2>

<ul>
<li><a href="https://medium.com/@danny.noam/http-based-contract-testing-gamesys-8c8d0d9aeee8">HTTP-Based Contract Testing @ Gamesys</a>. This is an interesting post discussing Contract Testing. Contract testing is testing between disparate, heterogenous components that interact via some binding interface. The interface is defined by a contract which defines the inputs and outputs between the components that are tested.</li>
</ul>

<h2 id="big-data">Big Data</h2>

<ul>
<li><a href="https://databricks.com/blog/2020/08/21/top-5-reasons-to-convert-your-cloud-data-lake-to-a-delta-lake.html">Top 5 Reasons to Convert Your Cloud Data Lake to a Delta Lake</a>. Databricks Delta Lake is an open-source storage layer that brings reliability to data lakes. The post linked to here discusses the benefits of using a Delta Lake on top of your data lake.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://medium.com/@denniszielke/continuous-kubernetes-blue-green-deployments-on-azure-using-nginx-appgateway-or-trafficmanager-4490bce29cb">Continuous Kubernetes blue-green deployments on Azure using Nginx, AppGateway or TrafficManager — part 2</a>. This is the second part of a series of posts around advanced deployment processes. In this post, the author takes us through how to do blue-green deployments using Azure Kubernetes Service (AKS). Very interesting!</li>
<li><a href="https://sbg.technology/2020/08/21/zero-downtime-kubernetes-deployments/">Zero-Downtime Kubernetes Deployments</a>. This post from one of <a href="/derivco">Derivco&rsquo;s</a> &ldquo;competitors&rdquo;, discusses how they do zero-downtime deployments. It is always interesting seeing how competitors are doing things!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-summit-2020-pro-tips-and-schedule/">How to Make the Most of Kafka Summit Virtually</a>. The, (virtual), Kafka Summit 2020, starts on Monday, (August 24). This post discusses how you - as an attendee - can get the most out of the conference. I will definitely be attending, and I hope I&rsquo;ll see you there!</li>
<li><a href="https://www.confluent.io/blog/testing-kafka-streams/">Testing Kafka Streams – A Deep Dive</a>. This awesome post looks at how to do automated Kafka Streams testing; what tools to use and some of the problems you can run into. As I said, it is an awesome post - and I will make sure that the developers in my team dealing with Kafka Streams read the post. Yes, I am looking at you Stevo, and at you Reinhardt!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>One of the largest data platform conferences takes place, (virtually), beginning of December this year: <a href="https://dataplatformgeeks.com/dps2020/"><strong>DATA PLATFORM VIRTUAL SUMMIT 2020</strong></a>, and the cool things is:</p>

<p><img src="/images/posts/Niels_Berglund.jpg" alt="" /></p>

<p><strong>Figure 1:</strong> <em>SQL Server &amp; Kafka</em></p>

<p>Yes, I am speaking at the conference! My topic is about, as you can see in <em>Figure 1</em>, the various ways we can stream data from SQL Server to Apache Kafka.</p>

<p>The conference has world class-speakers, (and me), so hurry up and <a href="https://dataplatformgeeks.com/dps2020/booking/">register</a>!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 33, 2020]]></title>
    <link href="https://nielsberglund.com/2020/08/16/interesting-stuff---week-33-2020/" rel="alternate" type="text/html"/>
    <updated>2020-08-16T09:54:48+02:00</updated>
    <id>https://nielsberglund.com/2020/08/16/interesting-stuff---week-33-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="azure-data-studio">Azure Data Studio</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2020/08/12/the-august-2020-release-of-azure-data-studio-is-now-available/">The August 2020 release of Azure Data Studio is now available</a>. As the title says, a new version of Azure Data Studio. There are quite a few Jupyter Notebooks enhancements in this release. Now I am waiting for the ability to execute individual lines of code in a Notebook cell.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://netflixtechblog.com/telltale-netflix-application-monitoring-simplified-5c08bfa780ba">Telltale: Netflix Application Monitoring Simplified</a>. This post about monitoring at Netflix came at a really good time for me, as at <a href="/derivco">Derivco</a> we are looking at improving our monitoring. So the post gives me food for thought.</li>
<li><a href="https://martinfowler.com/articles/patterns-of-distributed-systems/">Patterns of Distributed Systems</a>. This article came to my attention thanks to a colleague of mine - thanks, <a href="https://www.linkedin.com/in/scott-dukes-aaa49154/">Scott</a>! It discusses patterns for distributed systems, and how we can build up an understanding of how to better understand, communicate and teach distributed system design.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/ksqldb-state-stores-in-recovery/">The Curious Incident of the State Store in Recovery in ksqlDB</a>. This is a great article looking at the inner workings of ksqlDB. It is a must-read for anyone working with ksqlDB, (IMHO).</li>
<li><a href="https://www.confluent.io/blog/kafka-consumer-multi-threaded-messaging/">Multi-Threaded Message Consumption with the Apache Kafka Consumer</a>. Kafka consumers are not thread-safe, so you need to be very careful if you want to implement a multi-threaded consumer. The article linked to here drills down into the internals of Kafka consumers, and looks at how to create a multi-threaded consumer.</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>We are still in lockdown, but from tomorrow the restrictions are eased somewhat:</p>

<ul>
<li>Intra-province travel is allowed.</li>
<li>Bars and restaurants can sell alcohol.</li>
<li>Alcohol and cigarettes can be sold.</li>
</ul>

<p>Even though the restrictions are eased, I gather it will be a long time before we&rsquo;ll be back in the office. Oh, well - it is what it is.</p>

<p>On Tuesday, (Aug 18), I co-host the 4th installment of <a href="https://www.meetup.com/Azure-Transformation-Labs/events/272339566/">Azure Sketches</a>. In this session, we share our expertise and experience if you want to deliver remote working solutions to help inside a global pandemic. Fast, Remote, Agile Application and desktop solutions delivered through Azure. NGOs and Non-Profits are welcome.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 32, 2020]]></title>
    <link href="https://nielsberglund.com/2020/08/09/interesting-stuff---week-32-2020/" rel="alternate" type="text/html"/>
    <updated>2020-08-09T07:36:58+02:00</updated>
    <id>https://nielsberglund.com/2020/08/09/interesting-stuff---week-32-2020/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="azure-sql">Azure SQL</h2>

<ul>
<li><a href="https://techcommunity.microsoft.com/t5/azure-sql-database/learning-how-to-transition-your-sql-server-skills-to-azure-sql/ba-p/1571163">Learning How to Transition Your SQL Server Skills to Azure SQL | Data Exposed</a>. This post introduces courses and workshops for you to learn Azure SQL. I have had a look at the material, and it is awesome!</li>
</ul>

<h2 id="machine-learning">Machine Learning</h2>

<ul>
<li><a href="https://medium.com/dataseries/netflixs-polynote-is-a-new-open-source-framework-to-build-better-data-science-notebooks-4bdab6b8d0ae">Netflix’s Polynote is a New Open Source Framework to Build Better Data Science Notebooks</a>. In this post, the author discusses Polynote. Polynote is a new notebook environment which provides substantial improvements to streamline experimentation in machine learning workflows.</li>
<li><a href="https://www.infoq.com/articles/state-art-automl/">State of the Art in Automated Machine Learning</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article summarising a panel discussion where the panel members discussed the state of the art in automated machine learning (AutoML). Some very interesting ideas and thoughts!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/apache-kafka-2-6-updates/">What’s New in Apache Kafka 2.6</a>. The post linked to here discusses some of the new features in Kafka 2.6, which was released in early August. Some exciting things in the new release!</li>
<li><a href="https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">How Tencent PCG Uses Apache Kafka to Handle 10 Trillion+ Messages Per Day</a>. Tencent is one of the largest Kafka users in the world, processing trillions of messages every day. This article, introduces Tencent&rsquo;s journey of building federated Kafka clusters for business use cases that require high scalability and fault tolerance. Some very fascinating concepts in the post. I will definitely look at some of the things mentioned.</li>
<li><a href="https://www.confluent.io/blog/ksqldb-0-11-0-features-and-improvements/">Announcing ksqlDB 0.11.0</a>. Above I linked to a post related to a new Kafka release. The post here introduces a new ksqlDB release and looks at some of the new features.</li>
<li><a href="https://www.confluent.io/blog/confluent-cloud-for-apache-kafka-everywhere/">Project Metamorphosis Month 4: Confluent Cloud for Apache Kafka Available Everywhere</a>. This post announces how Confluent Cloud is now available on all major cloud providers! Expect a blog post where I look at Confluent Cloud on Azure.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
</feed>

