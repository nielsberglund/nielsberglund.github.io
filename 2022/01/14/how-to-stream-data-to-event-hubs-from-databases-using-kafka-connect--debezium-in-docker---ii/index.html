<!DOCTYPE html>
<html lang="en">
    
    

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.46" />

    
    
    

<title>How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - II • Niels Berglund</title>
<meta name="description" content="nielsb&#39;s blog :: technology musings about coding and data. Some topics: .NET, SQL Server, Data Science, R, Windows Azure and a lot more">
<meta name="keywords" content="sql server, c#, distributed computing, data science, microsoft r server, microsoft machine learning server, data science, sql server r services, sql server machine learning services, kafka, flink">
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - II"/>
<meta name="twitter:description" content="Here we look at the Debezium connector configuration needed if we want to stream data to Event Hubs."/>

<meta property="og:title" content="How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - II" />
<meta property="og:description" content="Here we look at the Debezium connector configuration needed if we want to stream data to Event Hubs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2022/01/14/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---ii/" />



<meta property="article:published_time" content="2022-01-14T05:25:03&#43;02:00"/>

<meta property="article:modified_time" content="2022-01-14T05:25:03&#43;02:00"/>












    

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/monokai.min.css">



<link rel="stylesheet" href="/css/hyde-hyde.css">
<link rel="stylesheet" href="/css/print.min.css" media="print">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    

</head>


    <body >
        
<div class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="">Niels Berglund</a>
      </span>
      
      <p class="site__description">
         Technology musings about coding and data. Some topics: .NET, SQL Server, Data Science, R, Windows Azure and a lot more. 
      </p>
      <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:inline-block;width:300px;height:250px"
     data-ad-client="ca-pub-3005153158271538"
     data-ad-slot="7704601332"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


      <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/">
						<span>Home</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/posts/">
						<span>Post Archive</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/series/">
						<span>Blog Post Series</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/presentations/">
						<span>Presentations</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/categories/">
						<span>Categories</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/tags/">
						<span>Tags</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/disclaimer/">
						<span>Disclaimer</span>
					</a>
				</li>
			 
		
		</li>
	</ul>
</div>

    
      <img src="/images/MVP_Logo_large.png"/>

    </div>

      
    
    <p>
      <section class="social">
	<h3 style="color:#ffffff">Follow Me:</h3>
	<a href="http://feeds.feedburner.com/manageddata/"><i class="fas fa-rss"></i></a>
	
	&nbsp;<a href="https://twitter.com/nielsberglund"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	&nbsp;<a href="https://github.com/nberglund"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	&nbsp;<a href="https://linkedin.com/in/niels-berglund-0122593"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	&nbsp;<a href="https://stackoverflow.com/users/7656880"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
</section>

    </p>
    <p class="copyright">
      &copy; 2022 nielsb.
      <a href="https://creativecommons.org/licenses/by-sa/4.0">Some Rights Reserved</a>.
      
    </p>
  </div>
  <div>
  </div>
</div>

        <div class="content container">
            
    <article>
  <header>
    <h1>How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - II</h1>
     
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Jan 14, 2022
    
    
    
      
      
          in
          
          
              <a class="post__category" href="/categories/debezium">DEBEZIUM</a>
              •
          
              <a class="post__category" href="/categories/event-hubs">EVENT HUBS</a>
              •
          
              <a class="post__category" href="/categories/kafka-connect">KAFKA CONNECT</a>
              
          
      
    
    
    
      
      
          <br/>
           <i class="fas fa-tags"></i>
          
          <a class="post__tag" href="/tags/cdc">cdc</a>
           
      
          <a class="post__tag" href="/tags/azure-event-hubs">azure event hubs</a>
           
      
          <a class="post__tag" href="/tags/kafka-connect">kafka connect</a>
           
      
          <a class="post__tag" href="/tags/streaming">streaming</a>
           
      
          <a class="post__tag" href="/tags/kafka">kafka</a>
           
      
          <a class="post__tag" href="/tags/azure">azure</a>
          
      
    
    
    <br/>
    <i class="fas fa-clock"></i> 12 min read
</div>


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3005153158271538"
     data-ad-slot="6668073777"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  </header>
  <div class="post">
    <p>In a two-post series, this second post looks at streaming data from a database to <strong>Azure Event Hubs</strong> using Kafka Connect and Debezium, where Kafka Connect and Debezium run in Docker.</p>

<p>The first post:</p>

<ul>
<li><a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/"><strong>How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - I</strong></a>. This post mainly looks at the configuration of Kafka Connect&rsquo;s <code>docker-compose.yml</code> file to allow us to connect to Event Hubs.</li>
</ul>

<p>This series came about as I in the post <a href="/2022/01/02/how-to-use-kafka-client-with-azure-event-hubs/"><strong>How to Use Kafka Client with Azure Event Hubs</strong></a>, somewhat foolishly said:</p>

<p><em>An interesting point here is that it is not only your Kafka applications that can publish to Event Hubs but any application that uses Kafka Client 1.0+, like Kafka Connect connectors!</em></p>

<p>I wrote the above without testing it myself, so when I was called out on it, I started researching (read &ldquo;Googling&rdquo;) to see if it was possible. The result of the &ldquo;Googling&rdquo; didn&rsquo;t give a 100% answer, so I decided to try it out, and this series is the result.</p>

<p>In the <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">first post</a>, - as mentioned - we configured Kafka Connect to connect into Event Hubs. In this post, we look at configuring the Debezium connector.</p>

<p></p>

<h2 id="pre-reqs">Pre-reqs</h2>

<p>The pre-reqs are the same as in <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/"><strong>How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - I</strong></a> and if you followed along in that post you should now have:</p>

<ul>
<li>A SQL Server database: <code>DebeziumTest</code> (or whatever you named it).</li>
<li>A table in the database: <code>dbo.tb_CDCTab1</code>.</li>
</ul>

<p>In addition to the above, you should also have an Event Hubs namespace. In the namespace you should have created a SAS policy connection string, where the connection string looks like so:</p>

<pre><code class="language-bash">Endpoint=sb://dbzeventhubs.servicebus.windows.net/; SharedAccessKeyName=KafkaConnect; \
SharedAccessKey=&lt;secret-key&gt;
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>SAS Policy Connection String</em></p>

<p>In <em>Code Snippet 1</em>, we see the policy connection string I created in the previous post.</p>

<h2 id="recap">Recap</h2>

<p>Before diving into configuring Debezium, let us recap what we did in the <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">previous post</a>, where we configured the <code>docker-compose.yml</code> file we use for Kafka Connect. In the last post, I divided the file into three parts to look at the details. Here I show the whole file with pointers to interesting areas:</p>

<p><img src="/images/posts/dbz-evthub-docker-compose-complete-1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Docker Compose File</em></p>

<p>The numbered/outlined areas in <em>Figure 1</em> refer to:</p>

<ol>
<li>The image we use. Here, we use the Kafka Connect base image, which contains the bare minimum for Kafka Connect.</li>
<li>Defines the Kafka endpoint for the worker process. This is the Kafka endpoint of the Event Hubs namespace for Event Hubs. You get the endpoint from the SAS policy&rsquo;s connection string, and you append it with port, <code>9093</code>, which is the Event Hubs Kafka API endpoint.</li>
<li>Kafka Connect uses topics to store connectors config, offsets, and statuses. As this is Event Hubs, we see the Event Hub names we want to use (they will be auto-created). We also define the replication factor for the event hubs (topics). In Kafka, the default is 3, but Event Hubs works somewhat differently, so we set the replication factor to 1.</li>

<li><p>This is the security/authentication configuration for the Kafka Connect worker process for connecting to the bootstrap server. Outlined in red, we see how we pass in the JAAS configuration. This is required as Kafka uses JAAS (Java Authentication and Authorization Service) for SASL. The JAAS configuration is based on the Event Hubs namespace configuration string and looks like so:</p>

<pre><code class="language-bash">CONNECT_SASL_JAAS_CONFIG: \ 
     &quot;org.apache.kafka.common.security.plain.PlainLoginModule \ 
      required username=\&quot;$$ConnectionString\&quot; \ 
      password=\&quot;Endpoint=sb://dbzeventhubs.servicebus.windows.net/; \
              SharedAccessKeyName=KafkaConnect; \ 
              SharedAccessKey=&lt;secret-key&gt;;&quot;\&quot;;&quot;
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>JAAS Configuration</em></p>

<p>Notice in <em>Figure 2</em> how we set the username to <code>$$ConnectionString</code> instead of the &ldquo;normal&rdquo; <code>$ConnectionString</code> as user name for Event Hubs. Using single <code>$</code> in <code>docker-compose</code> implies variable substitution, so therefore we &ldquo;escape&rdquo; by using <code>$$</code>.</p></li>

<li><p>This is the security/authentication configuration for the connector to connect to the bootstrap server. In this case the bootstrap server is the same for the worker process and the connector, so the JAAS configuration is the same as in <em>Code Snippet 2</em>.</p></li>

<li><p>We install/deploy Debezium&rsquo;s SQL Server connector using <code>confluent-hub install</code>.</p></li>
</ol>

<p>Two things to keep in mind in the Kafka Connect configuration are:</p>

<ul>
<li>Use <code>$$ConnectionString</code> instead of <code>$ConnectionString</code> as the user name when connecting to Event Hubs. Read <a href="/2022/01/02/how-to-use-kafka-client-with-azure-event-hubs/">this post</a> to see why we use <code>$ConnectionString</code> at all when connecting to Event Hubs.</li>
<li>Set the authentication/security for the connector as well, not only the Kafka Connect worker process.</li>
</ul>

<p>We have now reached more or less where we finished the <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">previous post</a>, let us continue.</p>

<h2 id="enable-cdc">Enable CDC</h2>

<p>When streaming data using Debezium, CDC (Change Data Capture) must be enabled. So let us enable CDC:</p>

<pre><code class="language-sql">USE DebeziumTest;
GO
-- before we enable CDC ensure the SQL Server Agent is started
-- we need first to enable CDC on the database
EXEC sys.sp_cdc_enable_db;

-- then we can enable CDC on the table
EXEC sys.sp_cdc_enable_table @source_schema = N'dbo',
                               @source_name   = N'tb_CDCTab1',
                               @role_name = NULL,
                               @supports_net_changes = 0;
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Enabling Database and Table for CDC</em></p>

<p>We see in <em>Code Snippet 3</em> how we:</p>

<ul>
<li>Enable CDC on the database.</li>
<li>After enabling CDC on the database, we enable it for the table(s) from which we want to capture changes.</li>
</ul>

<p>Please remember that the SQL Server Agent needs to be started before enabling CDC. Having enabled CDC, we can now look at the connector.</p>

<h2 id="debezium-connector">Debezium Connector</h2>

<p>Above, in <em>Figure 1</em>, we see how we install/deploy the SQL Server connector, and in the last post, we saw how the connector was loaded in the Kafka Connect worker process after we did <code>docker-compose up -d</code>.</p>

<p>The connector is loaded, but it is not doing anything. To enable the connector, we configure it using a JSON file, which we then <code>POST</code> to a Kafka Connect endpoint. To <code>POST</code> the file, you can use your favorite tool, Postman, <code>curl</code>, etc. I tend to like Postman, so that is what I use later on.</p>

<p>Before we go any further, even though this post looks in somewhat detail at configuring Debezium, it looks at it from the perspective of configuring it to be able to communicate with Event Hubs. So, if you want/need more information about Debezium configuration in general, look <a href="https://debezium.io/documentation/reference/stable/connectors/sqlserver.html">here</a>.</p>

<h4 id="debezium-event-hubs-topics">Debezium Event Hubs (Topics)</h4>

<p>During the configuration of the Debezium connector, two Debezium specific event hubs are created, regardless of the tables we are interested in:</p>

<ul>
<li>Event hub for schema changes. The connector writes schema change events to this event hub whenever a schema change happens for a captured table. The name of the event hub is the name in the <code>database.server.name</code> configuration property in the configuration file.</li>
<li>Event hub for database history. Schema changes are written to the schema change event hub, and also to this database history event hub. You set the name of this event hub in the <code>database.history.kafka.topic</code> configuration property in the configuration file.</li>
</ul>

<p>Let us look at database history configuration.</p>

<h4 id="database-history">Database History</h4>

<p>The database history requires some specific configuration. This caused me issues when I tried Debezium to Event Hubs, so I thought I better cover the database history configuration in a bit more detail.</p>

<blockquote>
<p><strong>NOTE:</strong> The database history properties are not SQL Server specific, but every Debezium connector requires them, except for the connectors for PostgreSQL, Cassandra, and Vitess.</p>
</blockquote>

<p>So, I mentioned above about the database history event hub and how the connector writes schema changes to that event hub. We define the event hub name in the <code>database.history.kafka.topic</code> configuration property. We also need to specify the endpoint where the event hub should be created/exists. We do that via the <code>database.history.kafka.bootstrap.servers</code> property. Keep in mind that the database history endpoint should be the same as the Kafka Connect process endpoint. That&rsquo;s what all documentation says anyway, and I have not tried anything differently.</p>

<blockquote>
<p><strong>NOTE:</strong> The timeout for creating the database history topic is very short, so when you connect to the cloud, whether it is Confluent Cloud or Azure Event Hubs, you should create the event hub (topic) manually. I.e. creating it before <code>POST</code>:ing the connector configuration. Oh, and when you create it, you have to create it with a partition count of 1.</p>
</blockquote>

<p>Taking the above into consideration, the database history configuration looks something like so:</p>

<pre><code class="language-bash"># more properties above

&quot;database.history.kafka.bootstrap.servers&quot;: &quot;dbzeventhubs.servicebus.windows.net:9093&quot;,
&quot;database.history.kafka.topic&quot;: &quot;dbzdbhistory&quot;,

# more properties below
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Database History Configuration</em></p>

<p>In <em>Code Snippet 4</em>, we see the database history configuration properties, and we see that <code>database.history.kafka.bootstrap.servers</code> has the same value as in <em>Figure 1</em>, point two. The event hub name is set to <code>dbzdbhistory</code>. As mentioned before, we should manually create that event hub to avoid timeout errors.</p>

<p>This looks good! But wait, there is more - and this was one of the things I completely missed when I initially tested Debezium with Event Hubs. What I missed was that if your Kafka cluster/Event Hubs is secured, you must add the security properties prefixed with <code>database.history.consumer.*</code> and <code>database.history.producer.*</code> to the connector configuration:</p>

<pre><code class="language-bash"># more properties above
# consumer
&quot;database.history.consumer.security.protocol&quot;:&quot;SASL_SSL&quot;,
&quot;database.history.consumer.sasl.mechanism&quot;:&quot;PLAIN&quot;,
&quot;database.history.consumer.sasl.jaas.config&quot;: &quot;&lt;JAAS-config-string&gt;;&quot;,
# producer
&quot;database.history.producer.security.protocol&quot;:&quot;SASL_SSL&quot;,
&quot;database.history.producer.sasl.mechanism&quot;:&quot;PLAIN&quot;,
&quot;database.history.producer.sasl.jaas.config&quot;:&quot;&lt;JAAS-config-string&gt;;&quot;
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Database History Security Configuration</em></p>

<p>In <em>Code Snippet 5</em>, we see how the database history security is set up like the security in <em>Figure 1</em>. One difference is that we set it up for both <code>consumer</code> and <code>producer</code>, as the connector will both write to and read from the topic. The JAAS configuration string looks like what we see in  <em>Code Snippet 2</em>; apart from that the user name is <code>$ConnectionString</code>. I.e. one dollar sign.</p>

<h4 id="configuration-file">Configuration File</h4>

<p>Having covered some of the essential parts of the connector configuration, let us look at what the complete configuration file looks like:</p>

<p><img src="/images/posts/dbz-evthub-dbz-connector-config.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Debezium Configuration File</em></p>

<p>Outlined in yellow in <em>Figure 2</em> are the configuration properties mostly related to the source database. Some properties to look at are:</p>

<ul>
<li><code>connector.class</code>: this defines what Debezium connector to use.</li>
<li><code>database.dbname</code>: the database from which we capture events.</li>
<li><code>database.server.name</code>: logical name that identifies the SQL Server instance (it can be an arbitrary string). An event hub with this name will be created to capture schema changes (as mentioned above). This name is also used as a prefix for all event hub names created by the connector for tables from which we capture changes.</li>
<li><code>table.include.list</code>: a comma-separated list of fully-qualified table names for tables from which we capture changes.</li>
</ul>

<p>The outlined in-red portion in <em>Figure 2</em> is required for <code>database.history.*</code>. Since I covered quite a lot about database history above, I will not go further into it.</p>

<h2 id="configure-the-connector">Configure the Connector</h2>

<p>We are now ready to &ldquo;spin up&rdquo; Kafka Connect, followed by configuring and enabling the connector.</p>

<blockquote>
<p><strong>NOTE:</strong> When I am testing things out, I ALWAYS tear down my environment before each run. I.e., delete the connector if it is created, take down Docker, and delete all relevant topics.</p>
</blockquote>

<p>Let&rsquo;s do this! We start with &ldquo;spinning up&rdquo; Kafka Connect like we did in the <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">last post</a>: <code>docker-compose up -d</code>. We wait a minute or two, and then we do the same checks as in the <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">previous post</a>:</p>

<ul>
<li>In the Azure portal, ensure that the Kafka Connect internal topics have been created. In my case, <code>offsets</code>, <code>status</code>, and <code>configs</code>.</li>
<li>Look and see that the connector is loaded: <code>GET http://127.0.0.1:8083/connector-plugins</code>.</li>
</ul>

<p>I don&rsquo;t know about you, but in my environment, it looks good. We are now ready to configure the connector. Before we do that, ensure that the database and table are CDC enabled and that you have manually created the database history event hub.</p>

<p>Now let&rsquo;s do it. Let us <code>POST</code> the configuration:</p>

<p><img src="/images/posts/dbz-evthub2-post-connector.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>POST Configuration</em></p>

<p>In <em>Figure 3</em>, we see our <code>POST</code> call (outlined in yellow) to the <code>connectors</code> endpoint (outlined in blue), and we also see part of the configuration file. When configuring a connector, we give it a name, and in my case, I named it <code>sql-server</code> (imaginative - I know). After we have <code>POST</code>:ed we see if it worked:</p>

<p><img src="/images/posts/dbz-evthub2-connector-status.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Connector Status</em></p>

<p>We see in <em>Figure 4</em> how we do a <code>GET</code> call against the <code>status</code> endpoint with the connector&rsquo;s name as part of the path. According to what is outlined in blue, all looks OK.</p>

<blockquote>
<p><strong>NOTE:</strong> When checking the status of a newly created connector, it is a good practice to wait a little while (10 - 20) seconds right after creation before checking the status. This is to give the connector some time to &ldquo;spin up&rdquo;. Alternatively, run the status check a couple of times.</p>
</blockquote>

<p>The other thing we can do to ensure all is OK is to look in the portal and see what event hubs we have:</p>

<p><img src="/images/posts/dbz-evthub2-topics-1.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Created Event Hubs</em></p>

<p>At first glance at <em>Figure 5</em> all looks OK. We see the connector&rsquo;s event hub for scheme changes (<code>debeziumtestserver</code>). So far, so good. But what about the event hub for the table we want to capture changes from: <code>dbo.tb_CDCTab1</code>? Where is that event hub? The answer to that is that the event hubs for capture table events are not created until an event happens:</p>

<pre><code class="language-sql">USE DebeziumTest;
GO

INSERT INTO dbo.tb_CDCTab1(Col1, Col2)
VALUES(1, 'Hello Number 1')
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Ingest Data</em></p>

<p>After executing the code in <em>Code Snippet 6</em>, you refresh the event hubs in the portal, and you see this:</p>

<p><img src="/images/posts/dbz-evthub2-table-topic.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>Event Hub for Table</em></p>

<p>After doing an insert in the table, we see in <em>Figure 6</em> an event hub created for that table. We assume that events have been published to the event hub. To further &ldquo;prove&rdquo; that, we look at that particular event hub&rsquo;s overview page in the portal and its stats:</p>

<p><img src="/images/posts/dbz-evthub2-table-events.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>Event Hub Stats</em></p>

<p>The stats for incoming messages are outlined in red in <em>Figure 7</em>, and we see how one message has arrived. It works - yay!</p>

<h2 id="summary">Summary</h2>

<p>In the <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">previous post</a> and this, we set out to see if we can use Debezium and Kafka Connect to stream data from databases to Event Hubs. We have now seen it is possible!</p>

<p>Things to keep in mind:</p>

<ul>
<li>When connecting to Event Hubs, we use the connection string from a SAS policy.</li>
<li>We use JAAS configuration to set the user name and password. For Event Hubs the username is the literal string <code>$ConnectionString</code>, and the password is the SAS policy&rsquo;s connection string.</li>
<li>If we use <code>docker-compose</code>, we set the user name in the JAAS configuration to <code>$$ConnectionString</code> to avoid variable substitution.</li>
<li>When configuring the security for Kafka Connect, you do it both for the Kafka Connect worker process and the connector.</li>
<li>Almost all Debezium connectors require a database history event hub (topic).</li>
<li>Since the timeout for automatic creation of the event hub is very short, the event hub should be created manually before configuring the connector.</li>
<li>We need to set security for the database history endpoint and do it for both consumer and producer (<code>database.history.consumer.*</code>, <code>database.history.producer.*</code>).</li>
</ul>

<p>Lastly, I would not have been able to get this to work if it hadn&rsquo;t been for the blog post:</p>

<ul>
<li><a href="https://rmoff.net/2019/10/16/using-kafka-connect-and-debezium-with-confluent-cloud/"><strong>Using Kafka Connect and Debezium with Confluent Cloud</strong></a>. This post by by Kafka guru <a href="https://twitter.com/rmoff">Robin Moffat</a> gave me the necessary pointers for the connector configuration - especially the security configuration for the database history event hub.</li>
</ul>

<p>As I said, <a href="https://twitter.com/rmoff">Robin Moffat</a> is a Kafka Guru, and if you are into Kafka, then you <strong>MUST</strong> read his <a href="https://rmoff.net/">blog</a>.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or [ping][ma] me.</p>
    <br/>
    
<h2>Blog Feed:</h2>
To automatically receive more posts like this, please
<a href="http://feeds.feedburner.com/manageddata/" target="_blank"> subscribe to my RSS/Atom feed</a> in your feed reader!</p>



  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3005153158271538"
     data-ad-slot="1158080725"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  

<div class="post--navigation post--navigation-single">
    
    <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/" class="post--navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - I</span>
    </a>
    
    
    <a href="/2022/01/16/interesting-stuff---week-2-2022/" class="post--navigation-next">
      <span class="navigation-tittle">Interesting Stuff - Week 2, 2022</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  


<div class="post__related">
    
    <h2>Related Articles</h2>
    <ul class="related-posts">
        
<li>
  <span class="list__title--small">
    <a href="/2022/01/10/how-to-stream-data-to-event-hubs-from-databases-using-kafka-connect--debezium-in-docker---i/">How to Stream Data to Event Hubs from Databases Using Kafka Connect &amp; Debezium in Docker - I</a>
      
      <time class="pull-right hidden-tablet">Jan 10 &#39;22</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2021/09/06/run-self-managed-kusto-kafka-connector-serverless-in-azure-container-instances/">Run Self-Managed Kusto Kafka Connector Serverless in Azure Container Instances</a>
      
      <time class="pull-right hidden-tablet">Sep 06 &#39;21</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2021/10/24/interesting-stuff---week-43-2021/">Interesting Stuff - Week 43, 2021</a>
      
      <time class="pull-right hidden-tablet">Oct 24 &#39;21</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2021/10/03/interesting-stuff---week-40-2021/">Interesting Stuff - Week 40, 2021</a>
      
      <time class="pull-right hidden-tablet">Oct 03 &#39;21</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2021/09/12/interesting-stuff---week-37-2021/">Interesting Stuff - Week 37, 2021</a>
      
      <time class="pull-right hidden-tablet">Sep 12 &#39;21</time>
      
  </span>
</li>

    </ul>
</div>



  
    
        <div id="disqus_thread"></div>
<script type="text/javascript">
    

    (function () {
    if (location.hostname === "localhost" ||
      location.hostname === "127.0.0.1" ||
      location.hostname === "") {
      return;
    }
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    var disqus_shortname = 'manageddata';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || 
      document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

<noscript>
  Please enable JavaScript to view the
  <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by
  <span class="logo-disqus">Disqus</span>
</a>

    


</article>


        </div>
        
    
  
  
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-18914734-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script defer src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"
  integrity="sha384-4oV5EgaV02iISL2ban6c/RmotsABqE4yZxZLcYMAdG7FAPsyHYAPpywE9PJo+Khy"
  crossorigin="anonymous">
</script>


<script src="/js/highlight.pack.js"></script>

<script type="text/javascript">
    hljs.configure({languages: []});
    hljs.initHighlightingOnLoad();
</script>



    



    </body>
</html>
