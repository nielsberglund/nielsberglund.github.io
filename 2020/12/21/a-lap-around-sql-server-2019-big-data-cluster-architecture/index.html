<!DOCTYPE html>
<html lang="en">
    
    

    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.46" />

    
    
    

<title>A Lap Around SQL Server 2019 Big Data Cluster: Architecture • Niels Berglund</title>
<meta name="description" content="nielsb&#39;s blog :: technology musings about coding and data. Some topics: .NET, SQL Server, Data Science, R, Windows Azure and a lot more">
<meta name="keywords" content="sql server, c#, distributed computing, data science, microsoft r server, microsoft machine learning server, data science, sql server r services, sql server machine learning services, kafka, flink">
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="A Lap Around SQL Server 2019 Big Data Cluster: Architecture"/>
<meta name="twitter:description" content="Here we look at the architecture of a SQL Server 2019 Big Data Cluster, and the various components."/>

<meta property="og:title" content="A Lap Around SQL Server 2019 Big Data Cluster: Architecture" />
<meta property="og:description" content="Here we look at the architecture of a SQL Server 2019 Big Data Cluster, and the various components." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2020/12/21/a-lap-around-sql-server-2019-big-data-cluster-architecture/" />



<meta property="article:published_time" content="2020-12-21T09:18:00&#43;02:00"/>

<meta property="article:modified_time" content="2020-12-21T09:18:00&#43;02:00"/>












    

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/monokai.min.css">



<link rel="stylesheet" href="/css/hyde-hyde.css">
<link rel="stylesheet" href="/css/print.min.css" media="print">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    

</head>


    <body >
        
<div class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="">Niels Berglund</a>
      </span>
      
      <p class="site__description">
         Technology musings about coding and data. Some topics: .NET, SQL Server, Data Science, R, Windows Azure and a lot more. 
      </p>
      <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:inline-block;width:300px;height:250px"
     data-ad-client="ca-pub-3005153158271538"
     data-ad-slot="7704601332"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


      <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/">
						<span>Home</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/posts/">
						<span>Post Archive</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/series/">
						<span>Blog Post Series</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/presentations/">
						<span>Presentations</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/categories/">
						<span>Categories</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/tags/">
						<span>Tags</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/disclaimer/">
						<span>Disclaimer</span>
					</a>
				</li>
			 
		
		</li>
	</ul>
</div>

    
      <img src="/images/MVP_Logo_large.png"/>

    </div>

      
    
    <p>
      <section class="social">
	<h3 style="color:#ffffff">Follow Me:</h3>
	<a href="http://feeds.feedburner.com/manageddata/"><i class="fas fa-rss"></i></a>
	
	&nbsp;<a href="https://twitter.com/nielsberglund"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	&nbsp;<a href="https://github.com/nberglund"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	&nbsp;<a href="https://linkedin.com/in/niels-berglund-0122593"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	&nbsp;<a href="https://stackoverflow.com/users/7656880"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
</section>

    </p>
    <p class="copyright">
      &copy; 2022 nielsb.
      <a href="https://creativecommons.org/licenses/by-sa/4.0">Some Rights Reserved</a>.
      
    </p>
  </div>
  <div>
  </div>
</div>

        <div class="content container">
            
    <article>
  <header>
    <h1>A Lap Around SQL Server 2019 Big Data Cluster: Architecture</h1>
     
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Dec 21, 2020
    
    
    
      
      
          in
          
          
              <a class="post__category" href="/categories/sql-server-2019">SQL SERVER 2019</a>
              •
          
              <a class="post__category" href="/categories/sql-server-2019-big-data-cluster">SQL SERVER 2019 BIG DATA CLUSTER</a>
              
          
      
    
    
    
      
      
          <br/>
           <i class="fas fa-tags"></i>
          
          <a class="post__tag" href="/tags/sql-server-2019-big-data-cluster">sql server 2019 big data cluster</a>
           
      
          <a class="post__tag" href="/tags/kubernetes">kubernetes</a>
           
      
          <a class="post__tag" href="/tags/azure-kubernetes-service">azure kubernetes service</a>
           
      
          <a class="post__tag" href="/tags/spark">spark</a>
           
      
          <a class="post__tag" href="/tags/hadoop">hadoop</a>
           
      
          <a class="post__tag" href="/tags/python">python</a>
          
      
    
    
    <br/>
    <i class="fas fa-clock"></i> 15 min read
</div>


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3005153158271538"
     data-ad-slot="6668073777"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  </header>
  <div class="post">
    <p>This post is the second in series about <strong>SQL Server 2019 Big Data Cluster</strong> based on a presentation I do: <strong>A Lap Around SQL Server 2019 Big Data Cluster</strong>.</p>

<p>In the first post <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/"><strong>A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</strong></a> we looked at - as the title implies - the background of SQL Server 2019 Big Data Cluster, (BDC), and the technology behind it.</p>

<p>In this post, we look at the architecture and components of a BDC.</p>

<p></p>

<p>Before we dive into the architecture, let&rsquo;s refresh our memories around what we covered in the <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">previous</a> post.</p>

<h2 id="recap">Recap</h2>

<p>We are getting more and more data, and the data comes in all types and sizes. We need a system to be able to manage, integrate, and analyze all this data. That&rsquo;s where SQL Server comes into the picture.</p>

<p>SQL Server has continuously evolved from its very humble beginnings based on Ashton Tate/Sybase code-base to where it is now:</p>

<ul>
<li>SQL Server in Linux.</li>
<li>SQL Server in Containers.</li>
<li>SQL Server on Kubernetes.</li>
</ul>

<p>With all the capabilities now in SQL Server, it is the ideal platform to handle big data.</p>

<p>The SQL Server itself is not enough to achieve what we want, so in addition to SQL Server a BDC includes quite a few open-source technologies:</p>

<ul>
<li>Apache Spark</li>
<li>Hadoop File System (HDFS)</li>
<li>Influx DB</li>
<li>Graphana</li>
<li>Kibana</li>
<li>Elasticsearch</li>
<li>more &hellip;</li>
</ul>

<p>Oh, and a BDC is not only one SQL server, but quite a few instances. The SQL Server instances are SQL on Linux containers, and the whole BDC are deployed to and runs on Kubernetes (k8s).</p>

<p>We spoke a bit about k8s, and what constitutes a k8s cluster, (nodes, pods, etc.). In the post we tried to illustrate a k8s cluster like so:</p>

<p><img src="/images/posts/bdc-lap-around-bdc-kubernetes-1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Kubernetes</em></p>

<p>In <em>Figure 1</em> we see some of the parts of a two-node Kubernetes cluster, with a Master node. Later in this post, we talk some more about the Master node, and the role it plays.</p>

<p>In the post, we briefly mentioned how we deploy a BDC, and we said we have essentially two options:</p>

<ul>
<li>Deploy via Python scripts.</li>
<li>Deploy using <strong>Azure Data Studio</strong>.</li>
</ul>

<p>We looked at how to manage and monitor a BDC, and we spoke about the tools for managing and monitoring:</p>

<ul>
<li><code>kubectl</code> - used to manage the Kubernetes cluster the BDC is deployed to.</li>
<li><code>azdata</code> - manage the BDC.</li>
</ul>

<p>In this post, looking at the architecture, we use the tools above, so ensure you have them installed if you want to follow along.</p>

<h2 id="architecture">Architecture</h2>

<p>How can we figure out what the architecture looks like? Well, in the <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/"><strong>A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</strong></a> post, we discussed k8s pods and how we could get information about the pod by executing some <code>kubectl</code> commands.</p>

<p>So let us go back to the pod we looked at briefly in the last post: <code>master-0</code>, which is the pod containing the SQL Server master instance. We look at that pod to see if we can get some information from it, which will help us in gaining insight into the architecture of a BDC. The code we use looks like so:</p>

<pre><code class="language-bash">kubectl get pods master-0 -n sqlbdc-cluster -o JSON
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Get Pod Information</em></p>

<p>In <em>Code Snippet 1</em> above we see how we use <code>kubectl get pods</code> and we:</p>

<ul>
<li>Send in the name of the pod we are interested in,</li>
<li>Indicate the k8s namespace the pod is in.</li>
<li>Want the output, <code>-o</code> flag, formatted as JSON.</li>
</ul>

<p>When we execute the code in <em>Code Snippet 1</em> we see something like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-pods1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Get Pods</em></p>

<p>The <code>kubectl get pods master-0</code> command returns all information about that particular pod, and in <em>Figure 2</em> we see the first 20 lines or so of the JSON output.</p>

<p>Notice the section outlined in red, the <code>metadata</code> section. This section contains general information about the pod, and if we look closer, we can see three labels outlined in, purple, yellow and green respectively:</p>

<ul>
<li><code>app</code> with a value of <code>master</code>.</li>
<li><code>plane</code> with a value of <code>data</code>.</li>
<li><code>role</code> with a value of <code>master-pool</code>.</li>
</ul>

<p>Maybe these labels would give us some insight if we were to look at all pods? Ok, so let&rsquo;s do that, and we will use some <code>kubectl -o</code> &ldquo;magic&rdquo; to get the information we want:</p>

<pre><code class="language-bash">kubectl get pods -n sqlbdc-cluster \ 
                 -o custom-columns=NAME:.metadata.name, \
                    APP:.metadata.labels.app, \
                    ROLE:.metadata.labels.role,\
                    PLANE:.metadata.labels.plane
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Custom Columns</em></p>

<p>To retrieve the information we want, we use the <code>custom-columns</code> output option. We see in <em>Code Snippet 2</em> how we say we want four columns back: <code>NAME</code>, <code>APP</code>, <code>ROLE, and</code>PLANE`, and what labels those are, (we talk more about labels below). We then execute:</p>

<p><img src="/images/posts/bdc-lap-around-arch-roles-planes.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Pods with Custom Output</em></p>

<p>In <em>Figure 3</em> we see the result from executing the code in <em>Code Snippet 2</em> and we see all pods in the <code>sqlbdc-cluster</code> namespace, i.e. all pods in the BDC. From the <code>PLANE</code> column we see how the BDC has two planes, the control plane and the data plane.</p>

<h4 id="control-data-plane">Control &amp; Data Plane</h4>

<p>Let us make a short diversion here and talk a bit about control and data planes.</p>

<p>In distributed systems/services, we need a way to manage and monitor our services, and that is the role of the control plane. In the previous <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">post</a> we spoke about the master node in a k8s cluster and how we interact with the master node for management of the cluster.</p>

<p>However, k8s has no idea about a SQL Server 2019 Big Data Cluster; in which order pods should be deployed etc. This is where the BDC control plane comes in. It knows about the BDC, so whenever there needs to be an interaction between the Kubernetes cluster and the BDC the k8s master node interacts with the BDC&rsquo;s control plane. Take a deployment as an example; when deploying to the BDC, the control plane acts as the coordinator and ensures services, etc., are &ldquo;spun up&rdquo; in the correct order.</p>

<p>That is, however, not the only thing the control plane does. Remember from my previous <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">post</a> how we briefly discussed monitoring of a BDC and how we said we use Grafana, and Kibana together with the underlying InfluxDB and EleasticSearch as persistent stores. Well, the control plane is also responsible for monitoring, and in <em>Figure 3</em> you see some examples of this, where there are <code>APP</code>&rsquo;s related to logs and metrics.</p>

<p>The data plane is what we communicate with when working with the BDC, doing queries etc. - the application traffic. In addition to that, the data plane is also responsible for:</p>

<ul>
<li>Routing.</li>
<li>Load balancing.</li>
<li>Observability.</li>
</ul>

<p>Now, knowing a bit about the planes, let us have a look at roles.</p>

<h4 id="role">role</h4>

<p>In Kubernetes, you have the notion of a <code>Role</code>, and that has to do with security: a <code>Role</code> sets permissions within a namespace. The <code>role</code> I refer to here has nothing to do with that. No, a <code>role</code> in this context is a label attributed to a pod in a k8s cluster.</p>

<blockquote>
<p><strong>NOTE:</strong> In <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">k8s documentation Labels</a> are described as follows: &ldquo;Labels are key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Labels can be used to organize and to select subsets of objects.&rdquo;</p>
</blockquote>

<p>Seeing the description about Labels above, we can deduce that a <code>role</code> describes the &ldquo;role&rdquo; of a Kubernetes component, i.e. what it does or belongs to. With that in mind, we can get some information/insight around the architecture of the BDC from it.</p>

<p>So let us once again look at the pods in the cluster and see what the <code>role</code> labels tell us:</p>

<pre><code class="language-bash">kubectl get pods -n sqlbdc-cluster2 \
                 -o custom-columns=PODNAME:.metadata.name,\
                 ROLE:.metadata.labels.role
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Pods &amp; Roles</em></p>

<p>The code in <em>Code Snippet 3</em> above is almost the same as in <em>Code Snippet 2</em>, but without the <code>APP</code> and <code>PLANE</code> columns. When we execute, we see:</p>

<p><img src="/images/posts/bdc-lap-around-arch-roles2.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Pods with Custom Output</em></p>

<p>In <em>Figure 4</em> we see how the various pods belong to quite few <code>ROLE</code>&rsquo;s. Some of the <code>ROLE</code>&rsquo;s we see are familiar, like: <code>controller</code> and <code>monitoring</code>, and we will not talk about them that much more. However, in <em>Figure 4</em> we also see some <code>ROLE</code>s named <code>xxx-pool</code>. Above we said that the <code>master-0</code> belonged to a role named <code>master-pool</code>, and we see that in <em>Figure 4</em> as well.</p>

<p>It turns out that the functionality, (SQL Server Master, Hadoop, etc.), of a BDC, is split into pools.</p>

<h2 id="pools">Pools</h2>

<p>When looking at <em>Figure 4</em> we see that we have different type of pools, and some of them have more than one pod. The pools are:</p>

<ul>
<li><code>compute-pool</code></li>
<li><code>data-pool</code></li>
<li><code>master-pool</code></li>
<li><code>storage-pool</code></li>
</ul>

<p>Let us look somewhat more in-depth into the pools above.</p>

<h4 id="master-pool">Master Pool</h4>

<p>From above we see how <code>master-0</code> belongs to the <code>master-pool</code>. In the last post as well as in this, we have mentioned how the <code>master-0</code> pod represents the SQL Server master instance, i.e. the &ldquo;normal&rdquo; SQL Server where your OLTP databases sit. So, let us see if we can prove that, by looking at what containers the pod has:</p>

<pre><code class="language-bash"> kubectl get pods master-0 -n sqlbdc-cluster2 \
                  -o custom-columns=PODNAME:.metadata.name,\
                     ROLE:.metadata.labels.role,\
                     CONTAINERS:.spec.containers[*].name
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Master Pod Containers</em></p>

<p>The code in <em>Code Snippet 4</em> is almost the same as in <em>Code Snippet 3</em>. The difference is that we also want to see the containers in the pod. When executing, we get:</p>

<p><img src="/images/posts/bdc-lap-around-arch-master-0-containers.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Containers in Master Pod</em></p>

<p>We see in <em>Figure 5</em> that the <code>master-0</code> pod is part of the <code>master-pool</code>, and it consists of three containers. From the <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">previous post</a> we already know about <code>collectd</code> and <code>fluentbit</code>. It is the third container, (first in the list), that is interesting - <code>mssql-server</code>, (highlighted in yellow).</p>

<p>To find out some more about the container we change the code in <em>Code Snippet 4</em> to the following:</p>

<pre><code class="language-bash"> kubectl get pods master-0 -n sqlbdc-cluster2 \
                  -o custom-columns=PODNAME:.metadata.name,\
                     CONTAINERS:.spec.containers[0].name,\
                     IMAGE:.spec.containers[0].image
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Container Image</em></p>

<p>In the code in <em>Code Snippet 5</em> we see how we retrieve the first container and the first image in the pod. We assume that as the SQL Server container is listed first, (see <em>Figure 5</em>), the container image will also be first. When we execute the code, the result looks like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-master-0-image.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>Containers in Master Pod</em></p>

<p>What we see in <em>Figure 6</em> is that the SQL Server instance in the master pool is SQL Server 2019 CU8, and it is SQL Server on Linux.</p>

<p>We will see later how there are more SQL Server instances in a BDC, but the master instance is what the user is interacting with. The master instance is also where read-write OLTP or dimensional data is stored, something like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-master-pool.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>BDC and Master Pool</em></p>

<p>What <em>Figure 7</em> shows us is a partial BDC cluster. The left is the control plane as discussed above and then beside it is the master pool with the one SQL Server instance.</p>

<p>At the bottom - outlined in red - we see a screen which illustrates a user and the interaction with the master instance. We also see a picture showing data stores (outlined in blue). What this means is that in SQL Server 2019, (not only BDC), you can query other data stores outside of SQL Server. This is thanks to Data Virtualization and PolyBase.</p>

<blockquote>
<p><strong>NOTE:</strong> A future post will cover Data Virtualization in SQL Server 2019 BDC.</p>
</blockquote>

<p>So, that is the master pool and the SQL Server master instance, what is next?</p>

<h4 id="compute-pool">Compute Pool</h4>

<p>In <em>Figure 4</em> we see how we have one pod belonging to the compute pool, the <code>compute-0-0</code>. Let us find out what containers are in the pod. We use code similar to <em>Code Snippet 4</em>, and when we execute we see:</p>

<p><img src="/images/posts/bdc-lap-around-arch-compute-containers.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Compute Pool Containers</em></p>

<p>Hmm, the compute pool pod looks the same as the master pool pod - a SQL Server instance. If we were to look at the container images, we&rsquo;d see the same as the master instance. So what is this?</p>

<p>As the name implies, the compute pool provides scale-out computational resources for a SQL Server BDC. They are used to offload computational work, or intermediate result sets, from the SQL Server master instance. For you who have worked with PolyBase before it is a fully configured Polybase Scale-Out Group.</p>

<p>The SQL Server instance in the compute pool is - as mentioned before - for computational purposes, not for storing data. The only time there may be data persistence is if it is needed for data shuffling, and in that case, <code>tempdb</code> is used.</p>

<p>If we add the compute pool to what we have in <em>Figure 7</em> we get something like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-compute-pool.png" alt="" /></p>

<p><strong>Figure 9:</strong> <em>Compute Pool</em></p>

<p>By looking at <em>Figure 9</em> we understand that the compute pool is mostly used when accessing external data, and we see more of this as we go along.</p>

<h4 id="data-pool">Data Pool</h4>

<p>When we look at <em>Figure 4</em> we see we have two pods belonging to the data pool. Let us run the same code as in <em>Figure 8</em> but replace <code>compute-0-0</code> with <code>data-0-0</code> and see what we get:</p>

<p><img src="/images/posts/bdc-lap-around-arch-data-0-containers.png" alt="" /></p>

<p><strong>Figure 10:</strong> <em>Data Pool &amp; Containers</em></p>

<p>In <em>Figure 10</em> we see the same as for the pods in the master and data pools, and if we looked at the second pod it would be the same; one SQL Server instance, together with <code>collectd</code> and <code>fluentbit</code>. So the only difference between the data pool and the other pools is that we have two SQL Server pods in the data pool. Building on the architectural diagram, it looks like so:</p>

<p><img src="/images/posts/bdc-lap-around-arch-data-pool.png" alt="" /></p>

<p><strong>Figure 11:</strong> <em>Data Pool</em></p>

<p>We see the data pool in <em>Figure 11</em>, and how it has the two SQL Server instances mentioned above. The reason it has two is that the data pool acts as a persisting and caching layer of external data. The data pool allows for performance querying of cached data against external data sources and offloading of work.</p>

<p>You ingest data into the data pool using either T-SQL queries or from Spark jobs. When you ingest data into the pool, the data is distributed into shards and stored across all SQL Server instances in the pool.</p>

<blockquote>
<p><strong>NOTE:</strong> The data pool is append only, you cannot edit data in the pool.</p>
</blockquote>

<p>At the beginning of the post, we mentioned Apache Spark and Hadoop, but so far we have only seen SQL Server &ldquo;stuff&rdquo;. Where is Hadoop?</p>

<h4 id="storage-pool">Storage Pool</h4>

<p>In the previous paragraph, we asked where Hadoop comes into the picture, and the answer to that is the storage pool. Let us have a look at one of the pods in the storage pool and see what information we get. We use the same code as for the other pods, and when we execute, we see:</p>

<p><img src="/images/posts/bdc-lap-around-arch-storage-0-containers.png" alt="" /></p>

<p><strong>Figure 12:</strong> <em>Storage Pool &amp; Containers</em></p>

<p>That is interesting! In <em>Figure 12</em> we see the &ldquo;usual suspects&rdquo;; <code>mssql-server</code>, <code>collectd</code>, and <code>fluentbit</code> - but we also see a container we haven&rsquo;t seen before: <code>hadoop</code>.</p>

<p>We have two pods in the storage pool, and the <code>hadoop</code> container in each pod forms part of a Hadoop cluster. The Hadoop container provides persistent storage for unstructured and semi-structured data. Data files, such as Parquet or delimited text, can be stored in the storage pool. Not only is the Hadoop File System, (HDFS), within the container but also Apache Spark:</p>

<p><img src="/images/posts/bdc-lap-around-arch-storage-pool.png" alt="" /></p>

<p><strong>Figure 13:</strong> <em>Storage Pool</em></p>

<p>We have added to our architectural diagram the storage pool cluster as in <em>Figure 13</em>, and at the bottom of the picture, outlined in red, something that looks like files. That represents the ability to mount external HDFS data sources into the storage pool cluster. You access the data via the SQL Server master instance, and PolyBase external tables or you can use the Apache Knox Gateway which sits in the Hadoop name-node: <code>nmnode-0-0</code>, which you see in <em>Figure 4</em>.</p>

<p>You may ask why we have SQL Server instances in the storage pool pods? The Big Data Cluster uses the SQL Servers to optimize the access of the data stored in the HDFS Data Nodes.</p>

<p>We have now looked at the various pools we listed at the beginning of this post, and we should have a relatively good grasp of the architecture of a SQL Server 2019 Big Data Cluster.</p>

<h2 id="applications">Applications</h2>

<p>However, there is one thing more to look at. If we look at <em>Figure 4</em> we see at the very top a pod named <code>appproxy-nsp2m</code>, and its role is <code>proxy</code>. What is this? Well, let us run the same code we have done so many times before and see that containers this pod has:</p>

<p><img src="/images/posts/bdc-lap-around-arch-appproxy-containers.png" alt="" /></p>

<p><strong>Figure 14:</strong> <em>Application Proxy</em></p>

<p>In <em>Figure 14</em> we see that the <code>appproxy-nsp2m</code> has a container named <code>app-service-proxy</code>. This container is used, amongst other things, to enable applications to be deployed to a BDC.</p>

<h4 id="application-pool">Application Pool</h4>

<p>The reason for deploying applications to the BDC is so the applications can benefit from the computational power of the cluster and can access the data that is available on the cluster. Supported runtimes are:</p>

<ul>
<li>R</li>
<li>Python</li>
<li>SSIS</li>
<li>MLeap</li>
</ul>

<p>When we deploy an application to a BDC, it is deployed into the Application Pool:</p>

<p><img src="/images/posts/bdc-lap-around-arch-application-pool.png" alt="" /></p>

<p><strong>Figure 15:</strong> <em>Application Proxy</em></p>

<p>What we see in <em>Figure 15</em> is an example of the application pool where we have a user, outlined in red, interacting with the applications in the pool.</p>

<h2 id="summary">Summary</h2>

<p>This is the second post in a series about SQL Server 2019 Big Data Cluster. In the first post: <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</a> we looked at the reason why SQL Server 2019 Big Data Cluster came about and the tech behind it.</p>

<p>In this post, we looked at the architecture of the BDC. We discussed in this post about:</p>

<ul>
<li>Master Pool: the master instance of SQL Server, which also acts as an entry point into the BDC.</li>
<li>Compute Pool: provides scale-out computational resources for a SQL Server big data cluster.</li>
<li>Data Pool: persistence and caching layer for external data.</li>
<li>Storage Pool: provides persistent storage for unstructured and semi-structured data.</li>
<li>Application Pool: hosts applications running inside the BDC.</li>
</ul>

<p>In future posts, we will look at data virtualization, and how the various pools work.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>
    <br/>
    
<h2>Blog Feed:</h2>
To automatically receive more posts like this, please
<a href="http://feeds.feedburner.com/manageddata/" target="_blank"> subscribe to my RSS/Atom feed</a> in your feed reader!</p>



  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3005153158271538"
     data-ad-slot="1158080725"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  

<div class="post--navigation post--navigation-single">
    
    <a href="/2020/12/13/interesting-stuff---week-50-2020/" class="post--navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Interesting Stuff - Week 50, 2020</span>
    </a>
    
    
    <a href="/2020/12/29/updated-bring-your-own-r--python-runtimes-to-sql-server-extensibility-framework/" class="post--navigation-next">
      <span class="navigation-tittle">UPDATED: Bring Your Own R &amp; Python Runtimes to SQL Server Extensibility Framework</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  


<div class="post__related">
    
    <h2>Related Articles</h2>
    <ul class="related-posts">
        
<li>
  <span class="list__title--small">
    <a href="/2020/04/26/a-lap-around-sql-server-2019-big-data-cluster-background--technology/">A Lap Around SQL Server 2019 Big Data Cluster: Background &amp; Technology</a>
      
      <time class="pull-right hidden-tablet">Apr 26 &#39;20</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2019/12/23/how-to-deploy-sql-server-2019-big-data-cluster-using-azure-data-studio/">How to Deploy SQL Server 2019 Big Data Cluster Using Azure Data Studio</a>
      
      <time class="pull-right hidden-tablet">Dec 23 &#39;19</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2019/09/11/install-sql-server-2019-big-data-cluster-using-azure-data-studio/">Install SQL Server 2019 Big Data Cluster using Azure Data Studio</a>
      
      <time class="pull-right hidden-tablet">Sep 11 &#39;19</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2018/11/11/interesting-stuff---week-45/">Interesting Stuff - Week 45</a>
      
      <time class="pull-right hidden-tablet">Nov 11 &#39;18</time>
      
  </span>
</li>

<li>
  <span class="list__title--small">
    <a href="/2018/11/10/sql-server-2019-big-data-cluster-on-azure-kubernetes-service/">SQL Server 2019 Big Data Cluster on Azure Kubernetes Service</a>
      
      <time class="pull-right hidden-tablet">Nov 10 &#39;18</time>
      
  </span>
</li>

    </ul>
</div>



  
    
        <div id="disqus_thread"></div>
<script type="text/javascript">
    

    (function () {
    if (location.hostname === "localhost" ||
      location.hostname === "127.0.0.1" ||
      location.hostname === "") {
      return;
    }
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    var disqus_shortname = 'manageddata';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || 
      document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

<noscript>
  Please enable JavaScript to view the
  <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by
  <span class="logo-disqus">Disqus</span>
</a>

    


</article>


        </div>
        
    
  
  
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-18914734-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script defer src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"
  integrity="sha384-4oV5EgaV02iISL2ban6c/RmotsABqE4yZxZLcYMAdG7FAPsyHYAPpywE9PJo+Khy"
  crossorigin="anonymous">
</script>


<script src="/js/highlight.pack.js"></script>

<script type="text/javascript">
    hljs.configure({languages: []});
    hljs.initHighlightingOnLoad();
</script>



    



    </body>
</html>
